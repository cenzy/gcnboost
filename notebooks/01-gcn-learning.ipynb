{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jbananafish/Desktop/Master/Thesis/code/gcnboost\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, RGCNConv, to_hetero\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from src.data.artgraph import ArtGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_data = ArtGraph(\"./ekg\", preprocess='node2vec', features=True, type='ekg')\n",
    "base_data = ArtGraph(\"data\", preprocess='node2vec', transform=T.ToUndirected(), features=True, type='ekg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some graph-level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of artist classes: 300\n",
      "Number of style classes: 83\n",
      "Number of genre classes: 50\n",
      "Number of input features: 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of artist classes: {base_data.num_classes['artist']}\")\n",
    "print(f\"Number of style classes: {base_data.num_classes['style']}\")\n",
    "print(f\"Number of genre classes: {base_data.num_classes['genre']}\")\n",
    "print(f\"Number of input features: {base_data.num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some node-level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = base_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1martwork\u001b[0m={\n",
      "    x=[61477, 128],\n",
      "    y_artist=[61477],\n",
      "    y_style=[61477],\n",
      "    y_genre=[61477],\n",
      "    train_mask=[61477],\n",
      "    val_mask=[61477],\n",
      "    test_mask=[61477]\n",
      "  },\n",
      "  \u001b[1martist\u001b[0m={ x=[300, 128] },\n",
      "  \u001b[1mgallery\u001b[0m={ x=[1090, 128] },\n",
      "  \u001b[1mcity\u001b[0m={ x=[665, 128] },\n",
      "  \u001b[1mcountry\u001b[0m={ x=[64, 128] },\n",
      "  \u001b[1mstyle\u001b[0m={ x=[83, 128] },\n",
      "  \u001b[1mperiod\u001b[0m={ x=[53, 128] },\n",
      "  \u001b[1mgenre\u001b[0m={ x=[50, 128] },\n",
      "  \u001b[1mserie\u001b[0m={ x=[610, 128] },\n",
      "  \u001b[1mauction\u001b[0m={ x=[5, 128] },\n",
      "  \u001b[1mtag\u001b[0m={ x=[5146, 128] },\n",
      "  \u001b[1mmedia\u001b[0m={ x=[160, 128] },\n",
      "  \u001b[1msubject\u001b[0m={ x=[2161, 128] },\n",
      "  \u001b[1mtraining_node\u001b[0m={ x=[108, 128] },\n",
      "  \u001b[1mfield\u001b[0m={ x=[65, 128] },\n",
      "  \u001b[1mmovement\u001b[0m={ x=[121, 128] },\n",
      "  \u001b[1mpeople\u001b[0m={ x=[48, 128] },\n",
      "  \u001b[1m(artist, influenced_rel, artist)\u001b[0m={ edge_index=[2, 62] },\n",
      "  \u001b[1m(artist, subject_rel, subject)\u001b[0m={ edge_index=[2, 3648] },\n",
      "  \u001b[1m(artist, training_rel, training_node)\u001b[0m={ edge_index=[2, 130] },\n",
      "  \u001b[1m(artist, field_rel, field)\u001b[0m={ edge_index=[2, 323] },\n",
      "  \u001b[1m(artist, movement_rel, movement)\u001b[0m={ edge_index=[2, 286] },\n",
      "  \u001b[1m(artist, patrons_rel, people)\u001b[0m={ edge_index=[2, 45] },\n",
      "  \u001b[1m(artist, teacher_rel, artist)\u001b[0m={ edge_index=[2, 12] },\n",
      "  \u001b[1m(gallery, city_rel, city)\u001b[0m={ edge_index=[2, 937] },\n",
      "  \u001b[1m(city, country_rel, country)\u001b[0m={ edge_index=[2, 581] },\n",
      "  \u001b[1m(gallery, country_rel, country)\u001b[0m={ edge_index=[2, 6] },\n",
      "  \u001b[1m(artwork, media_rel, media)\u001b[0m={ edge_index=[2, 56347] },\n",
      "  \u001b[1m(artwork, about_rel, tag)\u001b[0m={ edge_index=[2, 186612] },\n",
      "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
      "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
      "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] },\n",
      "  \u001b[1m(artwork, period_rel, period)\u001b[0m={ edge_index=[2, 5160] },\n",
      "  \u001b[1m(artwork, locatedin_rel, gallery)\u001b[0m={ edge_index=[2, 23508] },\n",
      "  \u001b[1m(artwork, auction_rel, auction)\u001b[0m={ edge_index=[2, 28] },\n",
      "  \u001b[1m(artwork, serie_rel, serie)\u001b[0m={ edge_index=[2, 5152] },\n",
      "  \u001b[1m(artwork, completedin_rel, city)\u001b[0m={ edge_index=[2, 4700] },\n",
      "  \u001b[1m(people, patrons_rel, artist)\u001b[0m={ edge_index=[2, 13] },\n",
      "  \u001b[1m(subject, rev_subject_rel, artist)\u001b[0m={ edge_index=[2, 3648] },\n",
      "  \u001b[1m(training_node, rev_training_rel, artist)\u001b[0m={ edge_index=[2, 130] },\n",
      "  \u001b[1m(field, rev_field_rel, artist)\u001b[0m={ edge_index=[2, 323] },\n",
      "  \u001b[1m(movement, rev_movement_rel, artist)\u001b[0m={ edge_index=[2, 286] },\n",
      "  \u001b[1m(people, rev_patrons_rel, artist)\u001b[0m={ edge_index=[2, 45] },\n",
      "  \u001b[1m(city, rev_city_rel, gallery)\u001b[0m={ edge_index=[2, 937] },\n",
      "  \u001b[1m(country, rev_country_rel, city)\u001b[0m={ edge_index=[2, 581] },\n",
      "  \u001b[1m(country, rev_country_rel, gallery)\u001b[0m={ edge_index=[2, 6] },\n",
      "  \u001b[1m(media, rev_media_rel, artwork)\u001b[0m={ edge_index=[2, 56347] },\n",
      "  \u001b[1m(tag, rev_about_rel, artwork)\u001b[0m={ edge_index=[2, 186612] },\n",
      "  \u001b[1m(genre, rev_genre_rel, artwork)\u001b[0m={ edge_index=[2, 61820] },\n",
      "  \u001b[1m(style, rev_style_rel, artwork)\u001b[0m={ edge_index=[2, 63157] },\n",
      "  \u001b[1m(artist, rev_author_rel, artwork)\u001b[0m={ edge_index=[2, 61477] },\n",
      "  \u001b[1m(period, rev_period_rel, artwork)\u001b[0m={ edge_index=[2, 5160] },\n",
      "  \u001b[1m(gallery, rev_locatedin_rel, artwork)\u001b[0m={ edge_index=[2, 23508] },\n",
      "  \u001b[1m(auction, rev_auction_rel, artwork)\u001b[0m={ edge_index=[2, 28] },\n",
      "  \u001b[1m(serie, rev_serie_rel, artwork)\u001b[0m={ edge_index=[2, 5152] },\n",
      "  \u001b[1m(city, rev_completedin_rel, artwork)\u001b[0m={ edge_index=[2, 4700] },\n",
      "  \u001b[1m(artist, rev_patrons_rel, people)\u001b[0m={ edge_index=[2, 13] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_homo = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[72206, 128], edge_index=[2, 947934], edge_type=[947934])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_homo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = SAGEConv((-1, -1), hidden_channels)\n",
    "            self.convs.append(conv)\n",
    "        self.conv_out = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "            x = F.dropout(x, self.dropout)\n",
    "        x = self.conv_out(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = GCNConv(128, hidden_channels)\n",
    "            self.convs.append(conv)\n",
    "        self.conv_out = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index).relu()\n",
    "            x = F.dropout(x, self.dropout)\n",
    "        x = self.conv_out(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, metadata, n_layers, dropout):\n",
    "        super(MGNN, self).__init__()\n",
    "        self.gnn_artist = GNN(hidden_channels, out_channels['artist'], n_layers, dropout)\n",
    "        self.gnn_artist = to_hetero(self.gnn_artist, metadata)\n",
    "\n",
    "        self.gnn_style = GNN(hidden_channels, out_channels['style'], n_layers, dropout)\n",
    "        self.gnn_style = to_hetero(self.gnn_style, metadata)\n",
    "\n",
    "        self.gnn_genre = GNN(hidden_channels, out_channels['genre'], n_layers, dropout)\n",
    "        self.gnn_genre = to_hetero(self.gnn_genre, metadata)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return [self.gnn_artist(x, edge_index), self.gnn_style(x, edge_index), self.gnn_genre(x, edge_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, n_layers, dropout):\n",
    "        super(MGCN, self).__init__()\n",
    "        self.gnn_artist = GCN(hidden_channels, out_channels['artist'], n_layers, dropout)\n",
    "\n",
    "        self.gnn_style = GCN(hidden_channels, out_channels['style'], n_layers, dropout)\n",
    "\n",
    "        self.gnn_genre = GCN(hidden_channels, out_channels['genre'], n_layers, dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return [self.gnn_artist(x, edge_index), self.gnn_style(x, edge_index), self.gnn_genre(x, edge_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtGraphGCNBoost:\n",
    "\n",
    "    map_labels = {\n",
    "        0: 'artist',\n",
    "        1: 'style',\n",
    "        2: 'genre'\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, data, optimizer):\n",
    "        \n",
    "        self.data = data\n",
    "        self.data_homo = data.to_homogeneous()\n",
    "        self.artworks = data['artwork']\n",
    "        self.y = torch.stack([data['artwork'].y_artist, data['artwork'].y_style, data['artwork'].y_genre])\n",
    "        self.train_mask = self.artworks.train_mask\n",
    "        self.val_mask = self.artworks.val_mask\n",
    "        self.test_mask = self.artworks.test_mask\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def get_classes(self, label= 'artist', split='train'):\n",
    "        pass \n",
    "\n",
    "    def get_accuracy(self, predicted, labels):\n",
    "        return predicted.argmax(dim=1).eq(labels).sum()/predicted.shape[0]\n",
    "\n",
    "    def get_accuracies_homo(self, predicted, labels, mask):\n",
    "        size = self.train_mask.shape[0]\n",
    "        accuracies = [] \n",
    "        for id, _ in self.map_labels.items():\n",
    "            accuracies.append(self.get_accuracy(predicted[id][:size][mask], labels[id][mask]))\n",
    "        return accuracies\n",
    "\n",
    "    def get_accuracies(self, predicted, labels, mask):\n",
    "        accuracies = [] \n",
    "        for id, _ in self.map_labels.items():\n",
    "            accuracies.append(self.get_accuracy(predicted[id]['artwork'][mask], labels[id][mask]))\n",
    "        return accuracies\n",
    "\n",
    "    def get_loss(self, predicted, labels):\n",
    "        return F.nll_loss(predicted, labels.type(torch.LongTensor))\n",
    "\n",
    "    def get_losses(self, predicted, labels, mask):\n",
    "        losses = []\n",
    "        for id, _ in self.map_labels.items():\n",
    "            losses.append(self.get_loss(predicted[id]['artwork'][mask], labels[id][mask]))\n",
    "        return losses\n",
    "\n",
    "    def get_losses_homo(self, predicted, labels, mask):\n",
    "        size = self.train_mask.shape[0]\n",
    "        losses = []\n",
    "        for id, _ in self.map_labels.items():\n",
    "            losses.append(self.get_loss(predicted[id][:size][mask], labels[id][mask]))\n",
    "        return losses\n",
    "\n",
    "\n",
    "    def multi_task_training(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        out = model(self.data.x_dict, self.data.edge_index_dict)\n",
    "        train_losses = self.get_losses(out, self.y, self.train_mask)\n",
    "        train_total_loss = sum(train_losses)\n",
    "        train_total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_accuracies = self.get_accuracies(out, self.y, self.train_mask)\n",
    "\n",
    "        return out, train_losses, train_accuracies\n",
    "\n",
    "    def multi_task_training_homo(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        out = model(self.data_homo.x, self.data_homo.edge_index)\n",
    "        train_losses = self.get_losses_homo(out, self.y, self.train_mask)\n",
    "        train_total_loss = sum(train_losses)\n",
    "        train_total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_accuracies = self.get_accuracies_homo(out, self.y, self.train_mask)\n",
    "\n",
    "        return out, train_losses, train_accuracies\n",
    "\n",
    "    def test(self, out):\n",
    "        val_losses = self.get_losses(out, self.y, self.val_mask)\n",
    "        test_losses = self.get_losses(out, self.y, self.test_mask)\n",
    "\n",
    "        val_accuracies = self.get_accuracies(out, self.y, self.val_mask)\n",
    "        test_accuracies = self.get_accuracies(out, self.y, self.test_mask)\n",
    "        \n",
    "        return val_losses, val_accuracies, test_losses, test_accuracies\n",
    "\n",
    "    def test_homo(self, out):\n",
    "        val_losses = self.get_losses_homo(out, self.y, self.val_mask)\n",
    "        test_losses = self.get_losses_homo(out, self.y, self.test_mask)\n",
    "\n",
    "        val_accuracies = self.get_accuracies_homo(out, self.y, self.val_mask)\n",
    "        test_accuracies = self.get_accuracies_homo(out, self.y, self.test_mask)\n",
    "        \n",
    "        return val_losses, val_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13953/574326720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_task_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13953/1967351676.py\u001b[0m in \u001b[0;36mmulti_task_training\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtrain_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13953/710230388.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_artist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_genre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mwrapped_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mwrapped_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<eval_with_key_3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mconvs_0__city3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry__rev_country_rel__city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__country\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__city\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__country__rev_country_rel__city\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mconvs_0__gallery3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountry__rev_country_rel__gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__country\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__gallery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__country__rev_country_rel__gallery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mconvs_0__artwork1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedia__rev_media_rel__artwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__media\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__media__rev_media_rel__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__media\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mconvs_0__artwork2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag__rev_about_rel__artwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__tag__rev_about_rel__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mconvs_0__artwork3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenre__rev_genre_rel__artwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__genre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__genre__rev_genre_rel__artwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__genre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msegment_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    340\u001b[0m                            reduce=self.aggr)\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_mean\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m                  dim_size: Optional[int] = None) -> torch.Tensor:\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mdim_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis-project/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MGNN(hidden_channels=16, out_channels=base_data.num_classes, metadata=data.metadata(),\n",
    "            n_layers=1, dropout=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "gcn = ArtGraphGCNBoost(model, data, optimizer)\n",
    "epochs = 1\n",
    "for epoch in range(0, epochs):\n",
    "    out, train_losses, train_accuracies = gcn.multi_task_training(epoch)\n",
    "    val_losses, val_accuracies, test_losses, test_accuracies = gcn.test(out)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'*\\tOn training')\n",
    "        for i, train_loss_acc in enumerate(zip(train_losses, train_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(train_loss_acc[0].detach().item(), 4)} \\t{round(train_loss_acc[1].item(), 2) * 100}%')\n",
    "        print(f'*\\tOn validation')\n",
    "        for i, val_loss_acc in enumerate(zip(val_losses, val_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(val_loss_acc[0].detach().item(), 4)} \\t{round(val_loss_acc[1].item(), 2) * 100}%')\n",
    "\n",
    "        print(f'*\\tOn test')\n",
    "        for i, test_loss_acc in enumerate(zip(test_losses, test_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(test_loss_acc[0].detach().item(), 4)} \\t{round(test_loss_acc[1].item(), 2) * 100}%')\n",
    "        \n",
    "#torch.save(out, \"out.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "*\tOn training\n",
      "\tartist\t 5.704 \t0.0%\n",
      "\tstyle\t 4.4586 \t1.0%\n",
      "\tgenre\t 3.8537 \t8.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.7025 \t1.0%\n",
      "\tstyle\t 4.4411 \t1.0%\n",
      "\tgenre\t 3.8763 \t8.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.7018 \t0.0%\n",
      "\tstyle\t 4.4389 \t1.0%\n",
      "\tgenre\t 3.8725 \t7.000000000000001%\n",
      "Epoch: 11\n",
      "*\tOn training\n",
      "\tartist\t 5.654 \t1.0%\n",
      "\tstyle\t 4.3648 \t1.0%\n",
      "\tgenre\t 3.7477 \t15.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.6621 \t2.0%\n",
      "\tstyle\t 4.3634 \t1.0%\n",
      "\tgenre\t 3.7951 \t14.000000000000002%\n",
      "*\tOn test\n",
      "\tartist\t 5.6633 \t1.0%\n",
      "\tstyle\t 4.3639 \t2.0%\n",
      "\tgenre\t 3.7968 \t15.0%\n",
      "Epoch: 21\n",
      "*\tOn training\n",
      "\tartist\t 5.6017 \t3.0%\n",
      "\tstyle\t 4.272 \t3.0%\n",
      "\tgenre\t 3.6431 \t22.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.6194 \t3.0%\n",
      "\tstyle\t 4.2853 \t4.0%\n",
      "\tgenre\t 3.7138 \t21.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.6227 \t2.0%\n",
      "\tstyle\t 4.2886 \t4.0%\n",
      "\tgenre\t 3.7209 \t22.0%\n",
      "Epoch: 31\n",
      "*\tOn training\n",
      "\tartist\t 5.544 \t4.0%\n",
      "\tstyle\t 4.1761 \t6.0%\n",
      "\tgenre\t 3.5368 \t32.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.5721 \t5.0%\n",
      "\tstyle\t 4.2034 \t8.0%\n",
      "\tgenre\t 3.6304 \t27.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.5778 \t4.0%\n",
      "\tstyle\t 4.2098 \t7.000000000000001%\n",
      "\tgenre\t 3.643 \t28.000000000000004%\n",
      "Epoch: 41\n",
      "*\tOn training\n",
      "\tartist\t 5.4789 \t5.0%\n",
      "\tstyle\t 4.0739 \t10.0%\n",
      "\tgenre\t 3.427 \t39.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.5185 \t6.0%\n",
      "\tstyle\t 4.1157 \t12.0%\n",
      "\tgenre\t 3.5438 \t33.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.5268 \t5.0%\n",
      "\tstyle\t 4.1252 \t10.0%\n",
      "\tgenre\t 3.5617 \t32.0%\n",
      "Epoch: 51\n",
      "*\tOn training\n",
      "\tartist\t 5.4049 \t6.0%\n",
      "\tstyle\t 3.9633 \t15.0%\n",
      "\tgenre\t 3.3124 \t42.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.4573 \t7.000000000000001%\n",
      "\tstyle\t 4.0199 \t18.0%\n",
      "\tgenre\t 3.4527 \t38.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.4689 \t6.0%\n",
      "\tstyle\t 4.0327 \t16.0%\n",
      "\tgenre\t 3.4763 \t36.0%\n",
      "Epoch: 61\n",
      "*\tOn training\n",
      "\tartist\t 5.3221 \t6.0%\n",
      "\tstyle\t 3.8425 \t21.0%\n",
      "\tgenre\t 3.1927 \t45.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.388 \t7.000000000000001%\n",
      "\tstyle\t 3.9142 \t25.0%\n",
      "\tgenre\t 3.3567 \t42.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.4034 \t6.0%\n",
      "\tstyle\t 3.9306 \t22.0%\n",
      "\tgenre\t 3.3862 \t39.0%\n",
      "Epoch: 71\n",
      "*\tOn training\n",
      "\tartist\t 5.2314 \t7.000000000000001%\n",
      "\tstyle\t 3.7115 \t24.0%\n",
      "\tgenre\t 3.068 \t47.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.3109 \t8.0%\n",
      "\tstyle\t 3.7985 \t28.999999999999996%\n",
      "\tgenre\t 3.2547 \t45.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.3307 \t6.0%\n",
      "\tstyle\t 3.8188 \t26.0%\n",
      "\tgenre\t 3.2907 \t41.0%\n",
      "Epoch: 81\n",
      "*\tOn training\n",
      "\tartist\t 5.1343 \t8.0%\n",
      "\tstyle\t 3.573 \t27.0%\n",
      "\tgenre\t 2.9407 \t48.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.2264 \t8.0%\n",
      "\tstyle\t 3.6742 \t33.0%\n",
      "\tgenre\t 3.1484 \t47.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.2515 \t7.000000000000001%\n",
      "\tstyle\t 3.6988 \t28.999999999999996%\n",
      "\tgenre\t 3.1911 \t42.0%\n",
      "Epoch: 91\n",
      "*\tOn training\n",
      "\tartist\t 5.0328 \t8.0%\n",
      "\tstyle\t 3.4309 \t28.999999999999996%\n",
      "\tgenre\t 2.8129 \t49.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.136 \t8.0%\n",
      "\tstyle\t 3.5436 \t36.0%\n",
      "\tgenre\t 3.0389 \t49.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.1671 \t7.000000000000001%\n",
      "\tstyle\t 3.5731 \t32.0%\n",
      "\tgenre\t 3.0888 \t43.0%\n",
      "Epoch: 101\n",
      "*\tOn training\n",
      "\tartist\t 4.9296 \t8.0%\n",
      "\tstyle\t 3.2893 \t31.0%\n",
      "\tgenre\t 2.686 \t50.0%\n",
      "*\tOn validation\n",
      "\tartist\t 5.0413 \t9.0%\n",
      "\tstyle\t 3.4087 \t40.0%\n",
      "\tgenre\t 2.9269 \t50.0%\n",
      "*\tOn test\n",
      "\tartist\t 5.0794 \t8.0%\n",
      "\tstyle\t 3.4437 \t35.0%\n",
      "\tgenre\t 2.9847 \t44.0%\n",
      "Epoch: 111\n",
      "*\tOn training\n",
      "\tartist\t 4.827 \t9.0%\n",
      "\tstyle\t 3.1532 \t33.0%\n",
      "\tgenre\t 2.5624 \t50.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.9442 \t10.0%\n",
      "\tstyle\t 3.2736 \t42.0%\n",
      "\tgenre\t 2.8144 \t51.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.9903 \t9.0%\n",
      "\tstyle\t 3.3151 \t37.0%\n",
      "\tgenre\t 2.8809 \t45.0%\n",
      "Epoch: 121\n",
      "*\tOn training\n",
      "\tartist\t 4.7267 \t10.0%\n",
      "\tstyle\t 3.0261 \t34.0%\n",
      "\tgenre\t 2.4445 \t51.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.8466 \t11.0%\n",
      "\tstyle\t 3.1421 \t42.0%\n",
      "\tgenre\t 2.7034 \t53.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.9013 \t10.0%\n",
      "\tstyle\t 3.1909 \t37.0%\n",
      "\tgenre\t 2.7792 \t46.0%\n",
      "Epoch: 131\n",
      "*\tOn training\n",
      "\tartist\t 4.6297 \t12.0%\n",
      "\tstyle\t 2.9095 \t34.0%\n",
      "\tgenre\t 2.3339 \t52.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.7497 \t13.0%\n",
      "\tstyle\t 3.0167 \t42.0%\n",
      "\tgenre\t 2.5954 \t53.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.814 \t12.0%\n",
      "\tstyle\t 3.0738 \t37.0%\n",
      "\tgenre\t 2.6811 \t46.0%\n",
      "Epoch: 141\n",
      "*\tOn training\n",
      "\tartist\t 4.536 \t14.000000000000002%\n",
      "\tstyle\t 2.8037 \t35.0%\n",
      "\tgenre\t 2.2313 \t52.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.6545 \t15.0%\n",
      "\tstyle\t 2.8988 \t43.0%\n",
      "\tgenre\t 2.4917 \t55.00000000000001%\n",
      "*\tOn test\n",
      "\tartist\t 4.729 \t13.0%\n",
      "\tstyle\t 2.9651 \t38.0%\n",
      "\tgenre\t 2.588 \t47.0%\n",
      "Epoch: 151\n",
      "*\tOn training\n",
      "\tartist\t 4.4452 \t15.0%\n",
      "\tstyle\t 2.7079 \t36.0%\n",
      "\tgenre\t 2.1372 \t53.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.5613 \t17.0%\n",
      "\tstyle\t 2.789 \t44.0%\n",
      "\tgenre\t 2.3934 \t56.00000000000001%\n",
      "*\tOn test\n",
      "\tartist\t 4.6466 \t14.000000000000002%\n",
      "\tstyle\t 2.8653 \t38.0%\n",
      "\tgenre\t 2.5006 \t47.0%\n",
      "Epoch: 161\n",
      "*\tOn training\n",
      "\tartist\t 4.357 \t16.0%\n",
      "\tstyle\t 2.6209 \t37.0%\n",
      "\tgenre\t 2.0511 \t54.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.4699 \t18.0%\n",
      "\tstyle\t 2.6873 \t46.0%\n",
      "\tgenre\t 2.301 \t56.99999999999999%\n",
      "*\tOn test\n",
      "\tartist\t 4.5667 \t15.0%\n",
      "\tstyle\t 2.7741 \t39.0%\n",
      "\tgenre\t 2.4195 \t48.0%\n",
      "Epoch: 171\n",
      "*\tOn training\n",
      "\tartist\t 4.2714 \t17.0%\n",
      "\tstyle\t 2.5414 \t38.0%\n",
      "\tgenre\t 1.9723 \t55.00000000000001%\n",
      "*\tOn validation\n",
      "\tartist\t 4.3806 \t18.0%\n",
      "\tstyle\t 2.593 \t47.0%\n",
      "\tgenre\t 2.2147 \t59.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.4893 \t16.0%\n",
      "\tstyle\t 2.6909 \t41.0%\n",
      "\tgenre\t 2.3449 \t49.0%\n",
      "Epoch: 181\n",
      "*\tOn training\n",
      "\tartist\t 4.1882 \t17.0%\n",
      "\tstyle\t 2.4678 \t39.0%\n",
      "\tgenre\t 1.9001 \t56.00000000000001%\n",
      "*\tOn validation\n",
      "\tartist\t 4.2932 \t19.0%\n",
      "\tstyle\t 2.505 \t49.0%\n",
      "\tgenre\t 2.1342 \t60.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.4144 \t17.0%\n",
      "\tstyle\t 2.6145 \t41.0%\n",
      "\tgenre\t 2.2762 \t51.0%\n",
      "Epoch: 191\n",
      "*\tOn training\n",
      "\tartist\t 4.1074 \t18.0%\n",
      "\tstyle\t 2.3991 \t41.0%\n",
      "\tgenre\t 1.8334 \t57.99999999999999%\n",
      "*\tOn validation\n",
      "\tartist\t 4.2076 \t20.0%\n",
      "\tstyle\t 2.4226 \t51.0%\n",
      "\tgenre\t 2.0592 \t61.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.3419 \t18.0%\n",
      "\tstyle\t 2.544 \t43.0%\n",
      "\tgenre\t 2.2133 \t52.0%\n",
      "Epoch: 201\n",
      "*\tOn training\n",
      "\tartist\t 4.0288 \t19.0%\n",
      "\tstyle\t 2.3344 \t42.0%\n",
      "\tgenre\t 1.7715 \t59.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.1238 \t21.0%\n",
      "\tstyle\t 2.3449 \t53.0%\n",
      "\tgenre\t 1.9889 \t63.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.2717 \t19.0%\n",
      "\tstyle\t 2.4785 \t44.0%\n",
      "\tgenre\t 2.1554 \t53.0%\n",
      "Epoch: 211\n",
      "*\tOn training\n",
      "\tartist\t 3.9522 \t20.0%\n",
      "\tstyle\t 2.2731 \t44.0%\n",
      "\tgenre\t 1.7135 \t61.0%\n",
      "*\tOn validation\n",
      "\tartist\t 4.0417 \t22.0%\n",
      "\tstyle\t 2.2712 \t55.00000000000001%\n",
      "\tgenre\t 1.9226 \t64.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.2038 \t20.0%\n",
      "\tstyle\t 2.4173 \t46.0%\n",
      "\tgenre\t 2.1017 \t54.0%\n",
      "Epoch: 221\n",
      "*\tOn training\n",
      "\tartist\t 3.8775 \t21.0%\n",
      "\tstyle\t 2.2146 \t46.0%\n",
      "\tgenre\t 1.659 \t62.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.9611 \t24.0%\n",
      "\tstyle\t 2.201 \t56.99999999999999%\n",
      "\tgenre\t 1.8601 \t65.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.138 \t21.0%\n",
      "\tstyle\t 2.3598 \t47.0%\n",
      "\tgenre\t 2.0521 \t55.00000000000001%\n",
      "Epoch: 231\n",
      "*\tOn training\n",
      "\tartist\t 3.8043 \t22.0%\n",
      "\tstyle\t 2.1587 \t48.0%\n",
      "\tgenre\t 1.6078 \t64.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.882 \t25.0%\n",
      "\tstyle\t 2.1339 \t57.99999999999999%\n",
      "\tgenre\t 1.8008 \t66.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.0742 \t22.0%\n",
      "\tstyle\t 2.3056 \t49.0%\n",
      "\tgenre\t 2.0062 \t55.00000000000001%\n",
      "Epoch: 241\n",
      "*\tOn training\n",
      "\tartist\t 3.7327 \t23.0%\n",
      "\tstyle\t 2.1053 \t50.0%\n",
      "\tgenre\t 1.5594 \t65.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.8042 \t26.0%\n",
      "\tstyle\t 2.0695 \t60.0%\n",
      "\tgenre\t 1.7446 \t68.0%\n",
      "*\tOn test\n",
      "\tartist\t 4.0122 \t23.0%\n",
      "\tstyle\t 2.2546 \t49.0%\n",
      "\tgenre\t 1.9635 \t56.00000000000001%\n",
      "Epoch: 251\n",
      "*\tOn training\n",
      "\tartist\t 3.6625 \t24.0%\n",
      "\tstyle\t 2.0539 \t51.0%\n",
      "\tgenre\t 1.5138 \t66.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.7278 \t28.000000000000004%\n",
      "\tstyle\t 2.0076 \t61.0%\n",
      "\tgenre\t 1.6912 \t69.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.952 \t24.0%\n",
      "\tstyle\t 2.2062 \t50.0%\n",
      "\tgenre\t 1.9238 \t56.99999999999999%\n",
      "Epoch: 261\n",
      "*\tOn training\n",
      "\tartist\t 3.5936 \t25.0%\n",
      "\tstyle\t 2.0048 \t53.0%\n",
      "\tgenre\t 1.4705 \t66.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.6527 \t28.999999999999996%\n",
      "\tstyle\t 1.9481 \t62.0%\n",
      "\tgenre\t 1.6404 \t70.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.8935 \t25.0%\n",
      "\tstyle\t 2.1604 \t51.0%\n",
      "\tgenre\t 1.887 \t57.99999999999999%\n",
      "Epoch: 271\n",
      "*\tOn training\n",
      "\tartist\t 3.5261 \t26.0%\n",
      "\tstyle\t 1.9577 \t54.0%\n",
      "\tgenre\t 1.4296 \t67.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.5789 \t30.0%\n",
      "\tstyle\t 1.8908 \t63.0%\n",
      "\tgenre\t 1.5921 \t71.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.8367 \t26.0%\n",
      "\tstyle\t 2.1172 \t52.0%\n",
      "\tgenre\t 1.8527 \t57.99999999999999%\n",
      "Epoch: 281\n",
      "*\tOn training\n",
      "\tartist\t 3.46 \t27.0%\n",
      "\tstyle\t 1.9126 \t55.00000000000001%\n",
      "\tgenre\t 1.3908 \t68.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.5063 \t31.0%\n",
      "\tstyle\t 1.8358 \t64.0%\n",
      "\tgenre\t 1.5462 \t71.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.7816 \t27.0%\n",
      "\tstyle\t 2.0763 \t52.0%\n",
      "\tgenre\t 1.821 \t59.0%\n",
      "Epoch: 291\n",
      "*\tOn training\n",
      "\tartist\t 3.3952 \t28.999999999999996%\n",
      "\tstyle\t 1.8694 \t56.00000000000001%\n",
      "\tgenre\t 1.354 \t68.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.4349 \t33.0%\n",
      "\tstyle\t 1.7829 \t65.0%\n",
      "\tgenre\t 1.5025 \t72.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.728 \t28.000000000000004%\n",
      "\tstyle\t 2.0378 \t53.0%\n",
      "\tgenre\t 1.7916 \t59.0%\n",
      "Epoch: 301\n",
      "*\tOn training\n",
      "\tartist\t 3.3317 \t30.0%\n",
      "\tstyle\t 1.8279 \t56.00000000000001%\n",
      "\tgenre\t 1.3191 \t69.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.3648 \t34.0%\n",
      "\tstyle\t 1.7321 \t66.0%\n",
      "\tgenre\t 1.4608 \t72.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.676 \t28.999999999999996%\n",
      "\tstyle\t 2.0015 \t53.0%\n",
      "\tgenre\t 1.7643 \t60.0%\n",
      "Epoch: 311\n",
      "*\tOn training\n",
      "\tartist\t 3.2695 \t31.0%\n",
      "\tstyle\t 1.7881 \t56.99999999999999%\n",
      "\tgenre\t 1.2859 \t69.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.296 \t35.0%\n",
      "\tstyle\t 1.6833 \t67.0%\n",
      "\tgenre\t 1.4211 \t73.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.6256 \t30.0%\n",
      "\tstyle\t 1.9674 \t54.0%\n",
      "\tgenre\t 1.739 \t60.0%\n",
      "Epoch: 321\n",
      "*\tOn training\n",
      "\tartist\t 3.2088 \t32.0%\n",
      "\tstyle\t 1.7499 \t57.99999999999999%\n",
      "\tgenre\t 1.2544 \t70.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.2286 \t36.0%\n",
      "\tstyle\t 1.6364 \t68.0%\n",
      "\tgenre\t 1.3833 \t74.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.5769 \t30.0%\n",
      "\tstyle\t 1.9352 \t54.0%\n",
      "\tgenre\t 1.7157 \t60.0%\n",
      "Epoch: 331\n",
      "*\tOn training\n",
      "\tartist\t 3.1494 \t33.0%\n",
      "\tstyle\t 1.7131 \t59.0%\n",
      "\tgenre\t 1.2244 \t70.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.1626 \t37.0%\n",
      "\tstyle\t 1.5914 \t69.0%\n",
      "\tgenre\t 1.3473 \t74.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.5299 \t31.0%\n",
      "\tstyle\t 1.9051 \t54.0%\n",
      "\tgenre\t 1.6941 \t61.0%\n",
      "Epoch: 341\n",
      "*\tOn training\n",
      "\tartist\t 3.0913 \t34.0%\n",
      "\tstyle\t 1.6778 \t59.0%\n",
      "\tgenre\t 1.1957 \t71.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.098 \t38.0%\n",
      "\tstyle\t 1.5482 \t70.0%\n",
      "\tgenre\t 1.313 \t75.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.4844 \t32.0%\n",
      "\tstyle\t 1.8768 \t55.00000000000001%\n",
      "\tgenre\t 1.6742 \t61.0%\n",
      "Epoch: 351\n",
      "*\tOn training\n",
      "\tartist\t 3.0347 \t35.0%\n",
      "\tstyle\t 1.6439 \t60.0%\n",
      "\tgenre\t 1.1685 \t71.0%\n",
      "*\tOn validation\n",
      "\tartist\t 3.0349 \t40.0%\n",
      "\tstyle\t 1.5067 \t71.0%\n",
      "\tgenre\t 1.2803 \t75.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.4406 \t33.0%\n",
      "\tstyle\t 1.8504 \t56.00000000000001%\n",
      "\tgenre\t 1.656 \t61.0%\n",
      "Epoch: 361\n",
      "*\tOn training\n",
      "\tartist\t 2.9794 \t36.0%\n",
      "\tstyle\t 1.6111 \t61.0%\n",
      "\tgenre\t 1.1426 \t72.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.9733 \t41.0%\n",
      "\tstyle\t 1.4668 \t71.0%\n",
      "\tgenre\t 1.2492 \t76.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.3984 \t34.0%\n",
      "\tstyle\t 1.8255 \t56.00000000000001%\n",
      "\tgenre\t 1.6392 \t62.0%\n",
      "Epoch: 371\n",
      "*\tOn training\n",
      "\tartist\t 2.9254 \t37.0%\n",
      "\tstyle\t 1.5795 \t61.0%\n",
      "\tgenre\t 1.1178 \t72.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.9132 \t42.0%\n",
      "\tstyle\t 1.4285 \t72.0%\n",
      "\tgenre\t 1.2195 \t77.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.3578 \t34.0%\n",
      "\tstyle\t 1.8022 \t56.99999999999999%\n",
      "\tgenre\t 1.6238 \t62.0%\n",
      "Epoch: 381\n",
      "*\tOn training\n",
      "\tartist\t 2.8729 \t38.0%\n",
      "\tstyle\t 1.549 \t62.0%\n",
      "\tgenre\t 1.0943 \t72.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.8545 \t43.0%\n",
      "\tstyle\t 1.3916 \t73.0%\n",
      "\tgenre\t 1.1913 \t77.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.3188 \t35.0%\n",
      "\tstyle\t 1.7804 \t56.99999999999999%\n",
      "\tgenre\t 1.6098 \t62.0%\n",
      "Epoch: 391\n",
      "*\tOn training\n",
      "\tartist\t 2.8217 \t39.0%\n",
      "\tstyle\t 1.5197 \t63.0%\n",
      "\tgenre\t 1.0718 \t73.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.7973 \t44.0%\n",
      "\tstyle\t 1.3563 \t74.0%\n",
      "\tgenre\t 1.1644 \t78.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.2814 \t36.0%\n",
      "\tstyle\t 1.7601 \t56.99999999999999%\n",
      "\tgenre\t 1.597 \t62.0%\n",
      "Epoch: 401\n",
      "*\tOn training\n",
      "\tartist\t 2.7717 \t40.0%\n",
      "\tstyle\t 1.4913 \t63.0%\n",
      "\tgenre\t 1.0504 \t73.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.7414 \t46.0%\n",
      "\tstyle\t 1.3222 \t74.0%\n",
      "\tgenre\t 1.1389 \t78.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.2455 \t37.0%\n",
      "\tstyle\t 1.7411 \t57.99999999999999%\n",
      "\tgenre\t 1.5855 \t62.0%\n",
      "Epoch: 411\n",
      "*\tOn training\n",
      "\tartist\t 2.7231 \t41.0%\n",
      "\tstyle\t 1.4638 \t64.0%\n",
      "\tgenre\t 1.03 \t74.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.687 \t47.0%\n",
      "\tstyle\t 1.2894 \t75.0%\n",
      "\tgenre\t 1.1146 \t78.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.2112 \t38.0%\n",
      "\tstyle\t 1.7233 \t57.99999999999999%\n",
      "\tgenre\t 1.5751 \t62.0%\n",
      "Epoch: 421\n",
      "*\tOn training\n",
      "\tartist\t 2.6758 \t42.0%\n",
      "\tstyle\t 1.4371 \t65.0%\n",
      "\tgenre\t 1.0105 \t74.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.6341 \t48.0%\n",
      "\tstyle\t 1.2577 \t75.0%\n",
      "\tgenre\t 1.0915 \t79.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.1783 \t38.0%\n",
      "\tstyle\t 1.7068 \t57.99999999999999%\n",
      "\tgenre\t 1.5657 \t62.0%\n",
      "Epoch: 431\n",
      "*\tOn training\n",
      "\tartist\t 2.6299 \t43.0%\n",
      "\tstyle\t 1.4112 \t65.0%\n",
      "\tgenre\t 0.9919 \t75.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.5827 \t49.0%\n",
      "\tstyle\t 1.2272 \t76.0%\n",
      "\tgenre\t 1.0694 \t79.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.1471 \t39.0%\n",
      "\tstyle\t 1.6913 \t59.0%\n",
      "\tgenre\t 1.5573 \t63.0%\n",
      "Epoch: 441\n",
      "*\tOn training\n",
      "\tartist\t 2.5854 \t44.0%\n",
      "\tstyle\t 1.3862 \t66.0%\n",
      "\tgenre\t 0.9741 \t75.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.5329 \t50.0%\n",
      "\tstyle\t 1.1978 \t77.0%\n",
      "\tgenre\t 1.0483 \t79.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.1174 \t39.0%\n",
      "\tstyle\t 1.6769 \t59.0%\n",
      "\tgenre\t 1.5496 \t63.0%\n",
      "Epoch: 451\n",
      "*\tOn training\n",
      "\tartist\t 2.5421 \t45.0%\n",
      "\tstyle\t 1.3618 \t66.0%\n",
      "\tgenre\t 0.9571 \t75.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.4845 \t51.0%\n",
      "\tstyle\t 1.1695 \t77.0%\n",
      "\tgenre\t 1.028 \t80.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.0891 \t40.0%\n",
      "\tstyle\t 1.6635 \t59.0%\n",
      "\tgenre\t 1.5428 \t63.0%\n",
      "Epoch: 461\n",
      "*\tOn training\n",
      "\tartist\t 2.5002 \t46.0%\n",
      "\tstyle\t 1.3381 \t67.0%\n",
      "\tgenre\t 0.9408 \t76.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.4376 \t52.0%\n",
      "\tstyle\t 1.1421 \t78.0%\n",
      "\tgenre\t 1.0086 \t80.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.0622 \t41.0%\n",
      "\tstyle\t 1.651 \t59.0%\n",
      "\tgenre\t 1.5368 \t63.0%\n",
      "Epoch: 471\n",
      "*\tOn training\n",
      "\tartist\t 2.4595 \t47.0%\n",
      "\tstyle\t 1.3151 \t67.0%\n",
      "\tgenre\t 0.9251 \t76.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.392 \t53.0%\n",
      "\tstyle\t 1.1156 \t78.0%\n",
      "\tgenre\t 0.9899 \t80.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.0367 \t41.0%\n",
      "\tstyle\t 1.6395 \t59.0%\n",
      "\tgenre\t 1.5314 \t63.0%\n",
      "Epoch: 481\n",
      "*\tOn training\n",
      "\tartist\t 2.42 \t48.0%\n",
      "\tstyle\t 1.2927 \t68.0%\n",
      "\tgenre\t 0.9101 \t76.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.3479 \t54.0%\n",
      "\tstyle\t 1.0899 \t79.0%\n",
      "\tgenre\t 0.972 \t80.0%\n",
      "*\tOn test\n",
      "\tartist\t 3.0126 \t41.0%\n",
      "\tstyle\t 1.6287 \t60.0%\n",
      "\tgenre\t 1.5266 \t63.0%\n",
      "Epoch: 491\n",
      "*\tOn training\n",
      "\tartist\t 2.3815 \t48.0%\n",
      "\tstyle\t 1.271 \t69.0%\n",
      "\tgenre\t 0.8957 \t77.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.305 \t55.00000000000001%\n",
      "\tstyle\t 1.0652 \t79.0%\n",
      "\tgenre\t 0.9548 \t81.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.9898 \t42.0%\n",
      "\tstyle\t 1.6189 \t60.0%\n",
      "\tgenre\t 1.5224 \t63.0%\n",
      "Epoch: 501\n",
      "*\tOn training\n",
      "\tartist\t 2.3442 \t49.0%\n",
      "\tstyle\t 1.2499 \t69.0%\n",
      "\tgenre\t 0.8818 \t77.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.2634 \t55.00000000000001%\n",
      "\tstyle\t 1.0414 \t80.0%\n",
      "\tgenre\t 0.9382 \t81.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.9682 \t42.0%\n",
      "\tstyle\t 1.6098 \t60.0%\n",
      "\tgenre\t 1.5187 \t63.0%\n",
      "Epoch: 511\n",
      "*\tOn training\n",
      "\tartist\t 2.308 \t50.0%\n",
      "\tstyle\t 1.2294 \t70.0%\n",
      "\tgenre\t 0.8685 \t77.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.2231 \t56.00000000000001%\n",
      "\tstyle\t 1.0184 \t80.0%\n",
      "\tgenre\t 0.9222 \t81.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.9479 \t43.0%\n",
      "\tstyle\t 1.6016 \t60.0%\n",
      "\tgenre\t 1.5155 \t63.0%\n",
      "Epoch: 521\n",
      "*\tOn training\n",
      "\tartist\t 2.2729 \t51.0%\n",
      "\tstyle\t 1.2094 \t70.0%\n",
      "\tgenre\t 0.8556 \t77.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.1841 \t56.00000000000001%\n",
      "\tstyle\t 0.9961 \t81.0%\n",
      "\tgenre\t 0.9067 \t81.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.9287 \t43.0%\n",
      "\tstyle\t 1.594 \t60.0%\n",
      "\tgenre\t 1.5128 \t63.0%\n",
      "Epoch: 531\n",
      "*\tOn training\n",
      "\tartist\t 2.2387 \t51.0%\n",
      "\tstyle\t 1.1899 \t70.0%\n",
      "\tgenre\t 0.8431 \t78.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.1463 \t56.99999999999999%\n",
      "\tstyle\t 0.9745 \t81.0%\n",
      "\tgenre\t 0.8918 \t82.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.9108 \t43.0%\n",
      "\tstyle\t 1.5872 \t60.0%\n",
      "\tgenre\t 1.5104 \t63.0%\n",
      "Epoch: 541\n",
      "*\tOn training\n",
      "\tartist\t 2.2056 \t52.0%\n",
      "\tstyle\t 1.1709 \t71.0%\n",
      "\tgenre\t 0.831 \t78.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.1097 \t56.99999999999999%\n",
      "\tstyle\t 0.9536 \t81.0%\n",
      "\tgenre\t 0.8773 \t82.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8939 \t44.0%\n",
      "\tstyle\t 1.5809 \t61.0%\n",
      "\tgenre\t 1.5084 \t63.0%\n",
      "Epoch: 551\n",
      "*\tOn training\n",
      "\tartist\t 2.1734 \t53.0%\n",
      "\tstyle\t 1.1523 \t71.0%\n",
      "\tgenre\t 0.8193 \t78.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.0741 \t57.99999999999999%\n",
      "\tstyle\t 0.9332 \t82.0%\n",
      "\tgenre\t 0.8632 \t82.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8781 \t44.0%\n",
      "\tstyle\t 1.5752 \t61.0%\n",
      "\tgenre\t 1.5068 \t64.0%\n",
      "Epoch: 561\n",
      "*\tOn training\n",
      "\tartist\t 2.1421 \t53.0%\n",
      "\tstyle\t 1.1342 \t72.0%\n",
      "\tgenre\t 0.808 \t78.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.0396 \t57.99999999999999%\n",
      "\tstyle\t 0.9136 \t82.0%\n",
      "\tgenre\t 0.8497 \t82.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8631 \t44.0%\n",
      "\tstyle\t 1.5702 \t61.0%\n",
      "\tgenre\t 1.5056 \t64.0%\n",
      "Epoch: 571\n",
      "*\tOn training\n",
      "\tartist\t 2.1116 \t54.0%\n",
      "\tstyle\t 1.1166 \t72.0%\n",
      "\tgenre\t 0.797 \t79.0%\n",
      "*\tOn validation\n",
      "\tartist\t 2.0061 \t59.0%\n",
      "\tstyle\t 0.8945 \t82.0%\n",
      "\tgenre\t 0.8365 \t83.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8492 \t44.0%\n",
      "\tstyle\t 1.5657 \t61.0%\n",
      "\tgenre\t 1.5046 \t64.0%\n",
      "Epoch: 581\n",
      "*\tOn training\n",
      "\tartist\t 2.0819 \t54.0%\n",
      "\tstyle\t 1.0993 \t73.0%\n",
      "\tgenre\t 0.7864 \t79.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.9736 \t60.0%\n",
      "\tstyle\t 0.876 \t83.0%\n",
      "\tgenre\t 0.8236 \t83.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8361 \t45.0%\n",
      "\tstyle\t 1.5617 \t61.0%\n",
      "\tgenre\t 1.504 \t64.0%\n",
      "Epoch: 591\n",
      "*\tOn training\n",
      "\tartist\t 2.053 \t55.00000000000001%\n",
      "\tstyle\t 1.0824 \t73.0%\n",
      "\tgenre\t 0.776 \t79.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.942 \t60.0%\n",
      "\tstyle\t 0.858 \t83.0%\n",
      "\tgenre\t 0.8112 \t83.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8239 \t45.0%\n",
      "\tstyle\t 1.5582 \t61.0%\n",
      "\tgenre\t 1.5036 \t64.0%\n",
      "Epoch: 601\n",
      "*\tOn training\n",
      "\tartist\t 2.0248 \t55.00000000000001%\n",
      "\tstyle\t 1.066 \t74.0%\n",
      "\tgenre\t 0.766 \t79.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.9113 \t61.0%\n",
      "\tstyle\t 0.8406 \t83.0%\n",
      "\tgenre\t 0.799 \t83.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.8126 \t46.0%\n",
      "\tstyle\t 1.5552 \t61.0%\n",
      "\tgenre\t 1.5035 \t64.0%\n",
      "Epoch: 611\n",
      "*\tOn training\n",
      "\tartist\t 1.9974 \t56.00000000000001%\n",
      "\tstyle\t 1.0499 \t74.0%\n",
      "\tgenre\t 0.7562 \t80.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.8814 \t61.0%\n",
      "\tstyle\t 0.8237 \t83.0%\n",
      "\tgenre\t 0.7872 \t83.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.802 \t46.0%\n",
      "\tstyle\t 1.5526 \t62.0%\n",
      "\tgenre\t 1.5036 \t64.0%\n",
      "Epoch: 621\n",
      "*\tOn training\n",
      "\tartist\t 1.9707 \t56.00000000000001%\n",
      "\tstyle\t 1.0341 \t74.0%\n",
      "\tgenre\t 0.7467 \t80.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.8524 \t62.0%\n",
      "\tstyle\t 0.8073 \t84.0%\n",
      "\tgenre\t 0.7758 \t84.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7922 \t46.0%\n",
      "\tstyle\t 1.5505 \t62.0%\n",
      "\tgenre\t 1.504 \t64.0%\n",
      "Epoch: 631\n",
      "*\tOn training\n",
      "\tartist\t 1.9446 \t56.99999999999999%\n",
      "\tstyle\t 1.0187 \t75.0%\n",
      "\tgenre\t 0.7374 \t80.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.8242 \t62.0%\n",
      "\tstyle\t 0.7913 \t84.0%\n",
      "\tgenre\t 0.7647 \t84.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7832 \t46.0%\n",
      "\tstyle\t 1.5489 \t62.0%\n",
      "\tgenre\t 1.5045 \t64.0%\n",
      "Epoch: 641\n",
      "*\tOn training\n",
      "\tartist\t 1.9193 \t56.99999999999999%\n",
      "\tstyle\t 1.0037 \t75.0%\n",
      "\tgenre\t 0.7284 \t80.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.7968 \t63.0%\n",
      "\tstyle\t 0.7759 \t84.0%\n",
      "\tgenre\t 0.7539 \t84.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7749 \t47.0%\n",
      "\tstyle\t 1.5477 \t62.0%\n",
      "\tgenre\t 1.5053 \t64.0%\n",
      "Epoch: 651\n",
      "*\tOn training\n",
      "\tartist\t 1.8945 \t57.99999999999999%\n",
      "\tstyle\t 0.989 \t75.0%\n",
      "\tgenre\t 0.7197 \t80.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.7701 \t63.0%\n",
      "\tstyle\t 0.761 \t85.0%\n",
      "\tgenre\t 0.7434 \t84.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7673 \t47.0%\n",
      "\tstyle\t 1.5468 \t62.0%\n",
      "\tgenre\t 1.5063 \t64.0%\n",
      "Epoch: 661\n",
      "*\tOn training\n",
      "\tartist\t 1.8704 \t57.99999999999999%\n",
      "\tstyle\t 0.9747 \t76.0%\n",
      "\tgenre\t 0.7112 \t81.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.7442 \t64.0%\n",
      "\tstyle\t 0.7465 \t85.0%\n",
      "\tgenre\t 0.7332 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7603 \t47.0%\n",
      "\tstyle\t 1.5464 \t62.0%\n",
      "\tgenre\t 1.5074 \t65.0%\n",
      "Epoch: 671\n",
      "*\tOn training\n",
      "\tartist\t 1.8468 \t59.0%\n",
      "\tstyle\t 0.9607 \t76.0%\n",
      "\tgenre\t 0.7029 \t81.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.719 \t64.0%\n",
      "\tstyle\t 0.7324 \t85.0%\n",
      "\tgenre\t 0.7233 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.754 \t47.0%\n",
      "\tstyle\t 1.5463 \t62.0%\n",
      "\tgenre\t 1.5088 \t65.0%\n",
      "Epoch: 681\n",
      "*\tOn training\n",
      "\tartist\t 1.8239 \t59.0%\n",
      "\tstyle\t 0.9469 \t76.0%\n",
      "\tgenre\t 0.6948 \t81.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.6944 \t64.0%\n",
      "\tstyle\t 0.7187 \t85.0%\n",
      "\tgenre\t 0.7136 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7484 \t48.0%\n",
      "\tstyle\t 1.5466 \t62.0%\n",
      "\tgenre\t 1.5103 \t65.0%\n",
      "Epoch: 691\n",
      "*\tOn training\n",
      "\tartist\t 1.8014 \t60.0%\n",
      "\tstyle\t 0.9335 \t77.0%\n",
      "\tgenre\t 0.6869 \t81.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.6706 \t65.0%\n",
      "\tstyle\t 0.7054 \t86.0%\n",
      "\tgenre\t 0.7042 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7433 \t48.0%\n",
      "\tstyle\t 1.5472 \t62.0%\n",
      "\tgenre\t 1.512 \t65.0%\n",
      "Epoch: 701\n",
      "*\tOn training\n",
      "\tartist\t 1.7795 \t60.0%\n",
      "\tstyle\t 0.9204 \t77.0%\n",
      "\tgenre\t 0.6793 \t81.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.6474 \t65.0%\n",
      "\tstyle\t 0.6925 \t86.0%\n",
      "\tgenre\t 0.695 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7388 \t48.0%\n",
      "\tstyle\t 1.5481 \t62.0%\n",
      "\tgenre\t 1.5138 \t65.0%\n",
      "Epoch: 711\n",
      "*\tOn training\n",
      "\tartist\t 1.7582 \t60.0%\n",
      "\tstyle\t 0.9076 \t77.0%\n",
      "\tgenre\t 0.6718 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.6248 \t66.0%\n",
      "\tstyle\t 0.6799 \t86.0%\n",
      "\tgenre\t 0.6861 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7349 \t48.0%\n",
      "\tstyle\t 1.5494 \t62.0%\n",
      "\tgenre\t 1.5158 \t65.0%\n",
      "Epoch: 721\n",
      "*\tOn training\n",
      "\tartist\t 1.7373 \t61.0%\n",
      "\tstyle\t 0.895 \t78.0%\n",
      "\tgenre\t 0.6645 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.6027 \t66.0%\n",
      "\tstyle\t 0.6677 \t86.0%\n",
      "\tgenre\t 0.6775 \t85.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7314 \t48.0%\n",
      "\tstyle\t 1.5509 \t62.0%\n",
      "\tgenre\t 1.5179 \t65.0%\n",
      "Epoch: 731\n",
      "*\tOn training\n",
      "\tartist\t 1.7169 \t61.0%\n",
      "\tstyle\t 0.8827 \t78.0%\n",
      "\tgenre\t 0.6575 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.5813 \t67.0%\n",
      "\tstyle\t 0.6558 \t86.0%\n",
      "\tgenre\t 0.6691 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7284 \t48.0%\n",
      "\tstyle\t 1.5527 \t62.0%\n",
      "\tgenre\t 1.5201 \t65.0%\n",
      "Epoch: 741\n",
      "*\tOn training\n",
      "\tartist\t 1.697 \t62.0%\n",
      "\tstyle\t 0.8707 \t78.0%\n",
      "\tgenre\t 0.6506 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.5604 \t67.0%\n",
      "\tstyle\t 0.6443 \t87.0%\n",
      "\tgenre\t 0.661 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.726 \t48.0%\n",
      "\tstyle\t 1.5548 \t62.0%\n",
      "\tgenre\t 1.5224 \t65.0%\n",
      "Epoch: 751\n",
      "*\tOn training\n",
      "\tartist\t 1.6775 \t62.0%\n",
      "\tstyle\t 0.8589 \t79.0%\n",
      "\tgenre\t 0.6439 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.54 \t67.0%\n",
      "\tstyle\t 0.6331 \t87.0%\n",
      "\tgenre\t 0.6531 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7239 \t48.0%\n",
      "\tstyle\t 1.5571 \t62.0%\n",
      "\tgenre\t 1.5248 \t65.0%\n",
      "Epoch: 761\n",
      "*\tOn training\n",
      "\tartist\t 1.6584 \t62.0%\n",
      "\tstyle\t 0.8475 \t79.0%\n",
      "\tgenre\t 0.6374 \t82.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.5203 \t67.0%\n",
      "\tstyle\t 0.6222 \t87.0%\n",
      "\tgenre\t 0.6454 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7224 \t49.0%\n",
      "\tstyle\t 1.5598 \t62.0%\n",
      "\tgenre\t 1.5274 \t65.0%\n",
      "Epoch: 771\n",
      "*\tOn training\n",
      "\tartist\t 1.6398 \t63.0%\n",
      "\tstyle\t 0.8363 \t79.0%\n",
      "\tgenre\t 0.631 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.501 \t67.0%\n",
      "\tstyle\t 0.6116 \t87.0%\n",
      "\tgenre\t 0.6379 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7213 \t49.0%\n",
      "\tstyle\t 1.5627 \t62.0%\n",
      "\tgenre\t 1.5301 \t65.0%\n",
      "Epoch: 781\n",
      "*\tOn training\n",
      "\tartist\t 1.6216 \t63.0%\n",
      "\tstyle\t 0.8253 \t79.0%\n",
      "\tgenre\t 0.6248 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.4822 \t68.0%\n",
      "\tstyle\t 0.6013 \t87.0%\n",
      "\tgenre\t 0.6306 \t86.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7206 \t49.0%\n",
      "\tstyle\t 1.5658 \t63.0%\n",
      "\tgenre\t 1.5328 \t65.0%\n",
      "Epoch: 791\n",
      "*\tOn training\n",
      "\tartist\t 1.6038 \t63.0%\n",
      "\tstyle\t 0.8146 \t80.0%\n",
      "\tgenre\t 0.6187 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.4639 \t68.0%\n",
      "\tstyle\t 0.5913 \t87.0%\n",
      "\tgenre\t 0.6234 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7204 \t49.0%\n",
      "\tstyle\t 1.5692 \t63.0%\n",
      "\tgenre\t 1.5357 \t65.0%\n",
      "Epoch: 801\n",
      "*\tOn training\n",
      "\tartist\t 1.5863 \t64.0%\n",
      "\tstyle\t 0.804 \t80.0%\n",
      "\tgenre\t 0.6127 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.446 \t68.0%\n",
      "\tstyle\t 0.5815 \t88.0%\n",
      "\tgenre\t 0.6165 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7205 \t49.0%\n",
      "\tstyle\t 1.5727 \t63.0%\n",
      "\tgenre\t 1.5386 \t65.0%\n",
      "Epoch: 811\n",
      "*\tOn training\n",
      "\tartist\t 1.5693 \t64.0%\n",
      "\tstyle\t 0.7937 \t80.0%\n",
      "\tgenre\t 0.6069 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.4286 \t69.0%\n",
      "\tstyle\t 0.572 \t88.0%\n",
      "\tgenre\t 0.6097 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.721 \t49.0%\n",
      "\tstyle\t 1.5764 \t63.0%\n",
      "\tgenre\t 1.5417 \t65.0%\n",
      "Epoch: 821\n",
      "*\tOn training\n",
      "\tartist\t 1.5525 \t64.0%\n",
      "\tstyle\t 0.7837 \t80.0%\n",
      "\tgenre\t 0.6012 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.4115 \t69.0%\n",
      "\tstyle\t 0.5627 \t88.0%\n",
      "\tgenre\t 0.6031 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7218 \t50.0%\n",
      "\tstyle\t 1.5803 \t63.0%\n",
      "\tgenre\t 1.5448 \t65.0%\n",
      "Epoch: 831\n",
      "*\tOn training\n",
      "\tartist\t 1.5362 \t65.0%\n",
      "\tstyle\t 0.7738 \t81.0%\n",
      "\tgenre\t 0.5956 \t83.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3949 \t69.0%\n",
      "\tstyle\t 0.5537 \t88.0%\n",
      "\tgenre\t 0.5966 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.723 \t50.0%\n",
      "\tstyle\t 1.5845 \t63.0%\n",
      "\tgenre\t 1.5479 \t65.0%\n",
      "Epoch: 841\n",
      "*\tOn training\n",
      "\tartist\t 1.5201 \t65.0%\n",
      "\tstyle\t 0.7642 \t81.0%\n",
      "\tgenre\t 0.5902 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3787 \t70.0%\n",
      "\tstyle\t 0.545 \t88.0%\n",
      "\tgenre\t 0.5903 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7244 \t50.0%\n",
      "\tstyle\t 1.5888 \t63.0%\n",
      "\tgenre\t 1.5511 \t65.0%\n",
      "Epoch: 851\n",
      "*\tOn training\n",
      "\tartist\t 1.5044 \t65.0%\n",
      "\tstyle\t 0.7547 \t81.0%\n",
      "\tgenre\t 0.5848 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3629 \t70.0%\n",
      "\tstyle\t 0.5364 \t88.0%\n",
      "\tgenre\t 0.5842 \t87.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7262 \t50.0%\n",
      "\tstyle\t 1.5933 \t63.0%\n",
      "\tgenre\t 1.5544 \t65.0%\n",
      "Epoch: 861\n",
      "*\tOn training\n",
      "\tartist\t 1.4889 \t66.0%\n",
      "\tstyle\t 0.7455 \t81.0%\n",
      "\tgenre\t 0.5796 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3475 \t70.0%\n",
      "\tstyle\t 0.5281 \t88.0%\n",
      "\tgenre\t 0.5782 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7284 \t50.0%\n",
      "\tstyle\t 1.598 \t63.0%\n",
      "\tgenre\t 1.5577 \t65.0%\n",
      "Epoch: 871\n",
      "*\tOn training\n",
      "\tartist\t 1.4738 \t66.0%\n",
      "\tstyle\t 0.7364 \t81.0%\n",
      "\tgenre\t 0.5745 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3324 \t70.0%\n",
      "\tstyle\t 0.52 \t88.0%\n",
      "\tgenre\t 0.5723 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7308 \t50.0%\n",
      "\tstyle\t 1.6029 \t63.0%\n",
      "\tgenre\t 1.5611 \t65.0%\n",
      "Epoch: 881\n",
      "*\tOn training\n",
      "\tartist\t 1.459 \t66.0%\n",
      "\tstyle\t 0.7275 \t82.0%\n",
      "\tgenre\t 0.5695 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3177 \t71.0%\n",
      "\tstyle\t 0.5122 \t89.0%\n",
      "\tgenre\t 0.5666 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7335 \t50.0%\n",
      "\tstyle\t 1.608 \t63.0%\n",
      "\tgenre\t 1.5645 \t65.0%\n",
      "Epoch: 891\n",
      "*\tOn training\n",
      "\tartist\t 1.4444 \t67.0%\n",
      "\tstyle\t 0.7188 \t82.0%\n",
      "\tgenre\t 0.5647 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.3033 \t71.0%\n",
      "\tstyle\t 0.5045 \t89.0%\n",
      "\tgenre\t 0.5611 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7365 \t50.0%\n",
      "\tstyle\t 1.6132 \t63.0%\n",
      "\tgenre\t 1.568 \t65.0%\n",
      "Epoch: 901\n",
      "*\tOn training\n",
      "\tartist\t 1.4301 \t67.0%\n",
      "\tstyle\t 0.7104 \t82.0%\n",
      "\tgenre\t 0.5599 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2892 \t71.0%\n",
      "\tstyle\t 0.4971 \t89.0%\n",
      "\tgenre\t 0.5556 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7396 \t50.0%\n",
      "\tstyle\t 1.6185 \t63.0%\n",
      "\tgenre\t 1.5715 \t65.0%\n",
      "Epoch: 911\n",
      "*\tOn training\n",
      "\tartist\t 1.4161 \t67.0%\n",
      "\tstyle\t 0.7021 \t82.0%\n",
      "\tgenre\t 0.5553 \t84.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2753 \t71.0%\n",
      "\tstyle\t 0.4899 \t89.0%\n",
      "\tgenre\t 0.5503 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.743 \t51.0%\n",
      "\tstyle\t 1.624 \t63.0%\n",
      "\tgenre\t 1.5751 \t65.0%\n",
      "Epoch: 921\n",
      "*\tOn training\n",
      "\tartist\t 1.4024 \t67.0%\n",
      "\tstyle\t 0.694 \t82.0%\n",
      "\tgenre\t 0.5507 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2619 \t71.0%\n",
      "\tstyle\t 0.4829 \t89.0%\n",
      "\tgenre\t 0.5451 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7468 \t51.0%\n",
      "\tstyle\t 1.6297 \t63.0%\n",
      "\tgenre\t 1.5788 \t65.0%\n",
      "Epoch: 931\n",
      "*\tOn training\n",
      "\tartist\t 1.3889 \t68.0%\n",
      "\tstyle\t 0.6861 \t83.0%\n",
      "\tgenre\t 0.5462 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2488 \t72.0%\n",
      "\tstyle\t 0.4761 \t89.0%\n",
      "\tgenre\t 0.54 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7507 \t51.0%\n",
      "\tstyle\t 1.6355 \t63.0%\n",
      "\tgenre\t 1.5824 \t65.0%\n",
      "Epoch: 941\n",
      "*\tOn training\n",
      "\tartist\t 1.3757 \t68.0%\n",
      "\tstyle\t 0.6783 \t83.0%\n",
      "\tgenre\t 0.5418 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.236 \t72.0%\n",
      "\tstyle\t 0.4695 \t89.0%\n",
      "\tgenre\t 0.5351 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7549 \t51.0%\n",
      "\tstyle\t 1.6414 \t63.0%\n",
      "\tgenre\t 1.5862 \t65.0%\n",
      "Epoch: 951\n",
      "*\tOn training\n",
      "\tartist\t 1.3627 \t68.0%\n",
      "\tstyle\t 0.6707 \t83.0%\n",
      "\tgenre\t 0.5375 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2235 \t72.0%\n",
      "\tstyle\t 0.4631 \t90.0%\n",
      "\tgenre\t 0.5302 \t88.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7593 \t51.0%\n",
      "\tstyle\t 1.6473 \t63.0%\n",
      "\tgenre\t 1.5899 \t65.0%\n",
      "Epoch: 961\n",
      "*\tOn training\n",
      "\tartist\t 1.35 \t68.0%\n",
      "\tstyle\t 0.6633 \t83.0%\n",
      "\tgenre\t 0.5332 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.2113 \t72.0%\n",
      "\tstyle\t 0.4568 \t90.0%\n",
      "\tgenre\t 0.5255 \t89.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7639 \t51.0%\n",
      "\tstyle\t 1.6534 \t63.0%\n",
      "\tgenre\t 1.5937 \t65.0%\n",
      "Epoch: 971\n",
      "*\tOn training\n",
      "\tartist\t 1.3375 \t69.0%\n",
      "\tstyle\t 0.656 \t83.0%\n",
      "\tgenre\t 0.5291 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.1993 \t72.0%\n",
      "\tstyle\t 0.4506 \t90.0%\n",
      "\tgenre\t 0.5208 \t89.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7688 \t51.0%\n",
      "\tstyle\t 1.6595 \t63.0%\n",
      "\tgenre\t 1.5975 \t65.0%\n",
      "Epoch: 981\n",
      "*\tOn training\n",
      "\tartist\t 1.3252 \t69.0%\n",
      "\tstyle\t 0.6489 \t84.0%\n",
      "\tgenre\t 0.525 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.1875 \t73.0%\n",
      "\tstyle\t 0.4447 \t90.0%\n",
      "\tgenre\t 0.5163 \t89.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.7738 \t51.0%\n",
      "\tstyle\t 1.6658 \t63.0%\n",
      "\tgenre\t 1.6014 \t65.0%\n",
      "Epoch: 991\n",
      "*\tOn training\n",
      "\tartist\t 1.3131 \t69.0%\n",
      "\tstyle\t 0.6419 \t84.0%\n",
      "\tgenre\t 0.5209 \t85.0%\n",
      "*\tOn validation\n",
      "\tartist\t 1.176 \t73.0%\n",
      "\tstyle\t 0.4388 \t90.0%\n",
      "\tgenre\t 0.5118 \t89.0%\n",
      "*\tOn test\n",
      "\tartist\t 2.779 \t51.0%\n",
      "\tstyle\t 1.6721 \t63.0%\n",
      "\tgenre\t 1.6052 \t65.0%\n"
     ]
    }
   ],
   "source": [
    "model = MGCN(hidden_channels=16, out_channels=base_data.num_classes,\n",
    "            n_layers=1, dropout=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "gcn = ArtGraphGCNBoost(model, data, optimizer)\n",
    "epochs = 1000\n",
    "for epoch in range(0, epochs):\n",
    "    out, train_losses, train_accuracies = gcn.multi_task_training_homo(epoch)\n",
    "    val_losses, val_accuracies, test_losses, test_accuracies = gcn.test_homo(out)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'*\\tOn training')\n",
    "        for i, train_loss_acc in enumerate(zip(train_losses, train_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(train_loss_acc[0].detach().item(), 4)} \\t{round(train_loss_acc[1].item(), 2) * 100}%')\n",
    "        print(f'*\\tOn validation')\n",
    "        for i, val_loss_acc in enumerate(zip(val_losses, val_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(val_loss_acc[0].detach().item(), 4)} \\t{round(val_loss_acc[1].item(), 2) * 100}%')\n",
    "\n",
    "        print(f'*\\tOn test')\n",
    "        for i, test_loss_acc in enumerate(zip(test_losses, test_accuracies)):\n",
    "            print(f'\\t{gcn.map_labels[i]}\\t {round(test_loss_acc[0].detach().item(), 4)} \\t{round(test_loss_acc[1].item(), 2) * 100}%')\n",
    "        \n",
    "#torch.save(out, \"out.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4cd95a69bfd7a84355187b639ae3e32d243eaa398007ea827fe1dce7201cea5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('thesis-project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
