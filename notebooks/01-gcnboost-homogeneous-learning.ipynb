{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jbananafish/Desktop/Master/Thesis/code/gcnboost\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, Linear, GraphConv, GATConv, to_hetero\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.nn as operators\n",
    "from sklearn.metrics import confusion_matrix as confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from src.data.artgraph import ArtGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://bicytour.altervista.org/artgraph-ekg/artgraph.zip\n",
      "Extracting data/artgraph/raw/artgraph.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#base_data = ArtGraph(\"./ekg\", preprocess='node2vec', features=True, type='ekg')\n",
    "base_data = ArtGraph(\"data\", preprocess='constant', features=True, type='ekg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = base_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1martwork\u001b[0m={\n",
       "    x=[61477, 128],\n",
       "    y_artist=[61477],\n",
       "    y_style=[61477],\n",
       "    y_genre=[61477],\n",
       "    train_mask=[61477],\n",
       "    val_mask=[61477],\n",
       "    test_mask=[61477]\n",
       "  },\n",
       "  \u001b[1martist\u001b[0m={ x=[300, 128] },\n",
       "  \u001b[1mgallery\u001b[0m={ x=[1090, 128] },\n",
       "  \u001b[1mcity\u001b[0m={ x=[665, 128] },\n",
       "  \u001b[1mcountry\u001b[0m={ x=[64, 128] },\n",
       "  \u001b[1mstyle\u001b[0m={ x=[83, 128] },\n",
       "  \u001b[1mperiod\u001b[0m={ x=[53, 128] },\n",
       "  \u001b[1mgenre\u001b[0m={ x=[50, 128] },\n",
       "  \u001b[1mserie\u001b[0m={ x=[610, 128] },\n",
       "  \u001b[1mauction\u001b[0m={ x=[5, 128] },\n",
       "  \u001b[1mtag\u001b[0m={ x=[5146, 128] },\n",
       "  \u001b[1mmedia\u001b[0m={ x=[160, 128] },\n",
       "  \u001b[1msubject\u001b[0m={ x=[2161, 128] },\n",
       "  \u001b[1mtraining_node\u001b[0m={ x=[108, 128] },\n",
       "  \u001b[1mfield\u001b[0m={ x=[65, 128] },\n",
       "  \u001b[1mmovement\u001b[0m={ x=[121, 128] },\n",
       "  \u001b[1mpeople\u001b[0m={ x=[48, 128] },\n",
       "  \u001b[1m(artist, influenced_rel, artist)\u001b[0m={ edge_index=[2, 31] },\n",
       "  \u001b[1m(artist, subject_rel, subject)\u001b[0m={ edge_index=[2, 3648] },\n",
       "  \u001b[1m(artist, training_rel, training_node)\u001b[0m={ edge_index=[2, 130] },\n",
       "  \u001b[1m(artist, field_rel, field)\u001b[0m={ edge_index=[2, 323] },\n",
       "  \u001b[1m(artist, movement_rel, movement)\u001b[0m={ edge_index=[2, 286] },\n",
       "  \u001b[1m(artist, patrons_rel, people)\u001b[0m={ edge_index=[2, 45] },\n",
       "  \u001b[1m(artist, teacher_rel, artist)\u001b[0m={ edge_index=[2, 6] },\n",
       "  \u001b[1m(gallery, city_rel, city)\u001b[0m={ edge_index=[2, 937] },\n",
       "  \u001b[1m(city, country_rel, country)\u001b[0m={ edge_index=[2, 581] },\n",
       "  \u001b[1m(gallery, country_rel, country)\u001b[0m={ edge_index=[2, 6] },\n",
       "  \u001b[1m(artwork, media_rel, media)\u001b[0m={ edge_index=[2, 56347] },\n",
       "  \u001b[1m(artwork, about_rel, tag)\u001b[0m={ edge_index=[2, 186612] },\n",
       "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] },\n",
       "  \u001b[1m(artwork, period_rel, period)\u001b[0m={ edge_index=[2, 5160] },\n",
       "  \u001b[1m(artwork, locatedin_rel, gallery)\u001b[0m={ edge_index=[2, 23508] },\n",
       "  \u001b[1m(artwork, auction_rel, auction)\u001b[0m={ edge_index=[2, 28] },\n",
       "  \u001b[1m(artwork, serie_rel, serie)\u001b[0m={ edge_index=[2, 5152] },\n",
       "  \u001b[1m(artwork, completedin_rel, city)\u001b[0m={ edge_index=[2, 4700] },\n",
       "  \u001b[1m(people, patrons_rel, artist)\u001b[0m={ edge_index=[2, 13] }\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 0.6379, -0.2165,  0.6949,  ...,  0.1997,  0.4008,  0.3378],\n",
       "        [ 0.0807, -0.0510, -0.1475,  ...,  0.1655, -0.4353,  0.1827],\n",
       "        [ 0.3808,  0.6442,  1.3926,  ...,  0.2606,  0.1476, -0.4818],\n",
       "        ...,\n",
       "        [ 0.4290, -0.1619,  0.3100,  ..., -0.2008, -0.0391,  0.4392],\n",
       "        [ 0.0748,  0.1289, -0.1568,  ..., -0.3241, -0.3156,  0.1110],\n",
       "        [ 0.1364, -0.2297,  1.2567,  ..., -0.3991,  0.1389,  0.0585]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['gallery']\n",
    "del data['city']\n",
    "del data['country']\n",
    "del data['auction']\n",
    "del data['media']\n",
    "del data['tag']\n",
    "del data['period']\n",
    "del data['serie']\n",
    "del data['subject']\n",
    "del data['field']\n",
    "del data['movement']\n",
    "del data['people']\n",
    "del data['training_node']\n",
    "\n",
    "del data['artwork', 'auction_rel', 'auction']\n",
    "del data['city', 'country_rel', 'country']\n",
    "del data['gallery', 'city_rel', 'city']\n",
    "del data['gallery', 'country_rel', 'country']\n",
    "del data['artwork', 'locatedin_rel', 'gallery']\n",
    "del data['artwork', 'completedin_rel', 'city']\n",
    "\n",
    "del data['artwork', 'media_rel', 'media']\n",
    "del data['artwork', 'about_rel', 'tag']\n",
    "del data['artwork', 'period_rel', 'period']\n",
    "del data['artwork', 'serie_rel', 'serie']\n",
    "del data['people', 'patrons_rel', 'artist']\n",
    "\n",
    "del data['artist', 'influenced_rel', 'artist']\n",
    "del data['artist', 'subject_rel', 'subject']\n",
    "del data['artist', 'training_rel', 'artist']\n",
    "del data['artist', 'training_rel', 'training_node']\n",
    "del data['artist', 'field_rel', 'field']\n",
    "del data['artist', 'movement_rel', 'movement']\n",
    "del data['artist', 'patrons_rel', 'people']\n",
    "del data['artist', 'teacher_rel', 'artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1martwork\u001b[0m={\n",
       "    x=[61477, 128],\n",
       "    y_artist=[61477],\n",
       "    y_style=[61477],\n",
       "    y_genre=[61477],\n",
       "    train_mask=[61477],\n",
       "    val_mask=[61477],\n",
       "    test_mask=[61477]\n",
       "  },\n",
       "  \u001b[1martist\u001b[0m={ x=[300, 128] },\n",
       "  \u001b[1mstyle\u001b[0m={ x=[83, 128] },\n",
       "  \u001b[1mgenre\u001b[0m={ x=[50, 128] },\n",
       "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] }\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1martwork\u001b[0m={\n",
       "    x=[61477, 128],\n",
       "    y_artist=[61477],\n",
       "    y_style=[61477],\n",
       "    y_genre=[61477],\n",
       "    train_mask=[61477],\n",
       "    val_mask=[61477],\n",
       "    test_mask=[61477]\n",
       "  },\n",
       "  \u001b[1martist\u001b[0m={ num_nodes=300 },\n",
       "  \u001b[1mgallery\u001b[0m={ num_nodes=1090 },\n",
       "  \u001b[1mcity\u001b[0m={ num_nodes=665 },\n",
       "  \u001b[1mcountry\u001b[0m={ num_nodes=64 },\n",
       "  \u001b[1mstyle\u001b[0m={ num_nodes=83 },\n",
       "  \u001b[1mperiod\u001b[0m={ num_nodes=53 },\n",
       "  \u001b[1mgenre\u001b[0m={ num_nodes=50 },\n",
       "  \u001b[1mserie\u001b[0m={ num_nodes=610 },\n",
       "  \u001b[1mauction\u001b[0m={ num_nodes=5 },\n",
       "  \u001b[1mtag\u001b[0m={ num_nodes=5146 },\n",
       "  \u001b[1mmedia\u001b[0m={ num_nodes=160 },\n",
       "  \u001b[1msubject\u001b[0m={ num_nodes=2161 },\n",
       "  \u001b[1mtraining_node\u001b[0m={ num_nodes=108 },\n",
       "  \u001b[1mfield\u001b[0m={ num_nodes=65 },\n",
       "  \u001b[1mmovement\u001b[0m={ num_nodes=121 },\n",
       "  \u001b[1mpeople\u001b[0m={ num_nodes=48 },\n",
       "  \u001b[1m(artist, influenced_rel, artist)\u001b[0m={ edge_index=[2, 62] },\n",
       "  \u001b[1m(artist, subject_rel, subject)\u001b[0m={ edge_index=[2, 3648] },\n",
       "  \u001b[1m(artist, training_rel, training_node)\u001b[0m={ edge_index=[2, 130] },\n",
       "  \u001b[1m(artist, field_rel, field)\u001b[0m={ edge_index=[2, 323] },\n",
       "  \u001b[1m(artist, movement_rel, movement)\u001b[0m={ edge_index=[2, 286] },\n",
       "  \u001b[1m(artist, patrons_rel, people)\u001b[0m={ edge_index=[2, 45] },\n",
       "  \u001b[1m(artist, teacher_rel, artist)\u001b[0m={ edge_index=[2, 12] },\n",
       "  \u001b[1m(gallery, city_rel, city)\u001b[0m={ edge_index=[2, 937] },\n",
       "  \u001b[1m(city, country_rel, country)\u001b[0m={ edge_index=[2, 581] },\n",
       "  \u001b[1m(gallery, country_rel, country)\u001b[0m={ edge_index=[2, 6] },\n",
       "  \u001b[1m(artwork, media_rel, media)\u001b[0m={ edge_index=[2, 56347] },\n",
       "  \u001b[1m(artwork, about_rel, tag)\u001b[0m={ edge_index=[2, 186612] },\n",
       "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] },\n",
       "  \u001b[1m(artwork, period_rel, period)\u001b[0m={ edge_index=[2, 5160] },\n",
       "  \u001b[1m(artwork, locatedin_rel, gallery)\u001b[0m={ edge_index=[2, 23508] },\n",
       "  \u001b[1m(artwork, auction_rel, auction)\u001b[0m={ edge_index=[2, 28] },\n",
       "  \u001b[1m(artwork, serie_rel, serie)\u001b[0m={ edge_index=[2, 5152] },\n",
       "  \u001b[1m(artwork, completedin_rel, city)\u001b[0m={ edge_index=[2, 4700] },\n",
       "  \u001b[1m(people, patrons_rel, artist)\u001b[0m={ edge_index=[2, 13] },\n",
       "  \u001b[1m(subject, rev_subject_rel, artist)\u001b[0m={ edge_index=[2, 3648] },\n",
       "  \u001b[1m(training_node, rev_training_rel, artist)\u001b[0m={ edge_index=[2, 130] },\n",
       "  \u001b[1m(field, rev_field_rel, artist)\u001b[0m={ edge_index=[2, 323] },\n",
       "  \u001b[1m(movement, rev_movement_rel, artist)\u001b[0m={ edge_index=[2, 286] },\n",
       "  \u001b[1m(people, rev_patrons_rel, artist)\u001b[0m={ edge_index=[2, 45] },\n",
       "  \u001b[1m(city, rev_city_rel, gallery)\u001b[0m={ edge_index=[2, 937] },\n",
       "  \u001b[1m(country, rev_country_rel, city)\u001b[0m={ edge_index=[2, 581] },\n",
       "  \u001b[1m(country, rev_country_rel, gallery)\u001b[0m={ edge_index=[2, 6] },\n",
       "  \u001b[1m(media, rev_media_rel, artwork)\u001b[0m={ edge_index=[2, 56347] },\n",
       "  \u001b[1m(tag, rev_about_rel, artwork)\u001b[0m={ edge_index=[2, 186612] },\n",
       "  \u001b[1m(genre, rev_genre_rel, artwork)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(style, rev_style_rel, artwork)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artist, rev_author_rel, artwork)\u001b[0m={ edge_index=[2, 61477] },\n",
       "  \u001b[1m(period, rev_period_rel, artwork)\u001b[0m={ edge_index=[2, 5160] },\n",
       "  \u001b[1m(gallery, rev_locatedin_rel, artwork)\u001b[0m={ edge_index=[2, 23508] },\n",
       "  \u001b[1m(auction, rev_auction_rel, artwork)\u001b[0m={ edge_index=[2, 28] },\n",
       "  \u001b[1m(serie, rev_serie_rel, artwork)\u001b[0m={ edge_index=[2, 5152] },\n",
       "  \u001b[1m(city, rev_completedin_rel, artwork)\u001b[0m={ edge_index=[2, 4700] },\n",
       "  \u001b[1m(artist, rev_patrons_rel, people)\u001b[0m={ edge_index=[2, 13] }\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_homogeneous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[72206, 128], edge_index=[2, 947934], edge_type=[947934])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = T.TwoHop()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some graph-level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of artist classes: 300\n",
      "Number of style classes: 83\n",
      "Number of genre classes: 50\n",
      "Number of input features: 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of artist classes: {base_data.num_classes['artist']}\")\n",
    "print(f\"Number of style classes: {base_data.num_classes['style']}\")\n",
    "print(f\"Number of genre classes: {base_data.num_classes['genre']}\")\n",
    "print(f\"Number of input features: {base_data.num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some node-level information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArtGraph()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = base_data[0]\n",
    "base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1martwork\u001b[0m={\n",
      "    num_nodes=61477,\n",
      "    y_artist=[61477],\n",
      "    y_style=[61477],\n",
      "    y_genre=[61477],\n",
      "    train_mask=[61477],\n",
      "    val_mask=[61477],\n",
      "    test_mask=[61477]\n",
      "  },\n",
      "  \u001b[1martist\u001b[0m={ num_nodes=300 },\n",
      "  \u001b[1mgallery\u001b[0m={ num_nodes=1090 },\n",
      "  \u001b[1mcity\u001b[0m={ num_nodes=665 },\n",
      "  \u001b[1mcountry\u001b[0m={ num_nodes=64 },\n",
      "  \u001b[1mstyle\u001b[0m={ num_nodes=83 },\n",
      "  \u001b[1mperiod\u001b[0m={ num_nodes=53 },\n",
      "  \u001b[1mgenre\u001b[0m={ num_nodes=50 },\n",
      "  \u001b[1mserie\u001b[0m={ num_nodes=610 },\n",
      "  \u001b[1mauction\u001b[0m={ num_nodes=5 },\n",
      "  \u001b[1mtag\u001b[0m={ num_nodes=5146 },\n",
      "  \u001b[1mmedia\u001b[0m={ num_nodes=160 },\n",
      "  \u001b[1msubject\u001b[0m={ num_nodes=2161 },\n",
      "  \u001b[1mtraining_node\u001b[0m={ num_nodes=108 },\n",
      "  \u001b[1mfield\u001b[0m={ num_nodes=65 },\n",
      "  \u001b[1mmovement\u001b[0m={ num_nodes=121 },\n",
      "  \u001b[1mpeople\u001b[0m={ num_nodes=48 },\n",
      "  \u001b[1m(artist, influenced_rel, artist)\u001b[0m={ edge_index=[2, 62] },\n",
      "  \u001b[1m(artist, subject_rel, subject)\u001b[0m={ edge_index=[2, 3648] },\n",
      "  \u001b[1m(artist, training_rel, training_node)\u001b[0m={ edge_index=[2, 130] },\n",
      "  \u001b[1m(artist, field_rel, field)\u001b[0m={ edge_index=[2, 323] },\n",
      "  \u001b[1m(artist, movement_rel, movement)\u001b[0m={ edge_index=[2, 286] },\n",
      "  \u001b[1m(artist, patrons_rel, people)\u001b[0m={ edge_index=[2, 45] },\n",
      "  \u001b[1m(artist, teacher_rel, artist)\u001b[0m={ edge_index=[2, 12] },\n",
      "  \u001b[1m(gallery, city_rel, city)\u001b[0m={ edge_index=[2, 937] },\n",
      "  \u001b[1m(city, country_rel, country)\u001b[0m={ edge_index=[2, 581] },\n",
      "  \u001b[1m(gallery, country_rel, country)\u001b[0m={ edge_index=[2, 6] },\n",
      "  \u001b[1m(artwork, media_rel, media)\u001b[0m={ edge_index=[2, 56347] },\n",
      "  \u001b[1m(artwork, about_rel, tag)\u001b[0m={ edge_index=[2, 186612] },\n",
      "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
      "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
      "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] },\n",
      "  \u001b[1m(artwork, period_rel, period)\u001b[0m={ edge_index=[2, 5160] },\n",
      "  \u001b[1m(artwork, locatedin_rel, gallery)\u001b[0m={ edge_index=[2, 23508] },\n",
      "  \u001b[1m(artwork, auction_rel, auction)\u001b[0m={ edge_index=[2, 28] },\n",
      "  \u001b[1m(artwork, serie_rel, serie)\u001b[0m={ edge_index=[2, 5152] },\n",
      "  \u001b[1m(artwork, completedin_rel, city)\u001b[0m={ edge_index=[2, 4700] },\n",
      "  \u001b[1m(people, patrons_rel, artist)\u001b[0m={ edge_index=[2, 13] },\n",
      "  \u001b[1m(subject, rev_subject_rel, artist)\u001b[0m={ edge_index=[2, 3648] },\n",
      "  \u001b[1m(training_node, rev_training_rel, artist)\u001b[0m={ edge_index=[2, 130] },\n",
      "  \u001b[1m(field, rev_field_rel, artist)\u001b[0m={ edge_index=[2, 323] },\n",
      "  \u001b[1m(movement, rev_movement_rel, artist)\u001b[0m={ edge_index=[2, 286] },\n",
      "  \u001b[1m(people, rev_patrons_rel, artist)\u001b[0m={ edge_index=[2, 45] },\n",
      "  \u001b[1m(city, rev_city_rel, gallery)\u001b[0m={ edge_index=[2, 937] },\n",
      "  \u001b[1m(country, rev_country_rel, city)\u001b[0m={ edge_index=[2, 581] },\n",
      "  \u001b[1m(country, rev_country_rel, gallery)\u001b[0m={ edge_index=[2, 6] },\n",
      "  \u001b[1m(media, rev_media_rel, artwork)\u001b[0m={ edge_index=[2, 56347] },\n",
      "  \u001b[1m(tag, rev_about_rel, artwork)\u001b[0m={ edge_index=[2, 186612] },\n",
      "  \u001b[1m(genre, rev_genre_rel, artwork)\u001b[0m={ edge_index=[2, 61820] },\n",
      "  \u001b[1m(style, rev_style_rel, artwork)\u001b[0m={ edge_index=[2, 63157] },\n",
      "  \u001b[1m(artist, rev_author_rel, artwork)\u001b[0m={ edge_index=[2, 61477] },\n",
      "  \u001b[1m(period, rev_period_rel, artwork)\u001b[0m={ edge_index=[2, 5160] },\n",
      "  \u001b[1m(gallery, rev_locatedin_rel, artwork)\u001b[0m={ edge_index=[2, 23508] },\n",
      "  \u001b[1m(auction, rev_auction_rel, artwork)\u001b[0m={ edge_index=[2, 28] },\n",
      "  \u001b[1m(serie, rev_serie_rel, artwork)\u001b[0m={ edge_index=[2, 5152] },\n",
      "  \u001b[1m(city, rev_completedin_rel, artwork)\u001b[0m={ edge_index=[2, 4700] },\n",
      "  \u001b[1m(artist, rev_patrons_rel, people)\u001b[0m={ edge_index=[2, 13] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['gallery']\n",
    "del data['city']\n",
    "del data['country']\n",
    "del data['auction']\n",
    "\n",
    "del data['artwork', 'auction_rel', 'auction']\n",
    "del data['auction', 'rev_auction_rel', 'artwork']\n",
    "\n",
    "del data['city', 'country_rel', 'country']\n",
    "del data['country', 'rev_country_rel', 'city']\n",
    "\n",
    "del data['gallery', 'city_rel', 'city']\n",
    "del data['city', 'rev_city_rel', 'gallery']\n",
    "\n",
    "del data['gallery', 'country_rel', 'country']\n",
    "del data['country', 'rev_country_rel', 'gallery']\n",
    "\n",
    "del data['artwork', 'locatedin_rel', 'gallery']\n",
    "del data['gallery', 'rev_locatedin_rel', 'artwork']\n",
    "\n",
    "del data['artwork', 'completedin_rel', 'city']\n",
    "del data['city', 'rev_completedin_rel', 'artwork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1martwork\u001b[0m={\n",
       "    x=[61477, 128],\n",
       "    y_artist=[61477],\n",
       "    y_style=[61477],\n",
       "    y_genre=[61477],\n",
       "    train_mask=[61477],\n",
       "    val_mask=[61477],\n",
       "    test_mask=[61477]\n",
       "  },\n",
       "  \u001b[1martist\u001b[0m={ x=[300, 128] },\n",
       "  \u001b[1mstyle\u001b[0m={ x=[83, 128] },\n",
       "  \u001b[1mperiod\u001b[0m={ x=[53, 128] },\n",
       "  \u001b[1mgenre\u001b[0m={ x=[50, 128] },\n",
       "  \u001b[1mserie\u001b[0m={ x=[610, 128] },\n",
       "  \u001b[1mtag\u001b[0m={ x=[5146, 128] },\n",
       "  \u001b[1mmedia\u001b[0m={ x=[160, 128] },\n",
       "  \u001b[1msubject\u001b[0m={ x=[2161, 128] },\n",
       "  \u001b[1mtraining_node\u001b[0m={ x=[108, 128] },\n",
       "  \u001b[1mfield\u001b[0m={ x=[65, 128] },\n",
       "  \u001b[1mmovement\u001b[0m={ x=[121, 128] },\n",
       "  \u001b[1mpeople\u001b[0m={ x=[48, 128] },\n",
       "  \u001b[1m(artist, influenced_rel, artist)\u001b[0m={ edge_index=[2, 62] },\n",
       "  \u001b[1m(artist, subject_rel, subject)\u001b[0m={ edge_index=[2, 3648] },\n",
       "  \u001b[1m(artist, training_rel, training_node)\u001b[0m={ edge_index=[2, 130] },\n",
       "  \u001b[1m(artist, field_rel, field)\u001b[0m={ edge_index=[2, 323] },\n",
       "  \u001b[1m(artist, movement_rel, movement)\u001b[0m={ edge_index=[2, 286] },\n",
       "  \u001b[1m(artist, patrons_rel, people)\u001b[0m={ edge_index=[2, 45] },\n",
       "  \u001b[1m(artist, teacher_rel, artist)\u001b[0m={ edge_index=[2, 12] },\n",
       "  \u001b[1m(artwork, media_rel, media)\u001b[0m={ edge_index=[2, 56347] },\n",
       "  \u001b[1m(artwork, about_rel, tag)\u001b[0m={ edge_index=[2, 186612] },\n",
       "  \u001b[1m(artwork, genre_rel, genre)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(artwork, style_rel, style)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artwork, author_rel, artist)\u001b[0m={ edge_index=[2, 61477] },\n",
       "  \u001b[1m(artwork, period_rel, period)\u001b[0m={ edge_index=[2, 5160] },\n",
       "  \u001b[1m(artwork, serie_rel, serie)\u001b[0m={ edge_index=[2, 5152] },\n",
       "  \u001b[1m(people, patrons_rel, artist)\u001b[0m={ edge_index=[2, 13] },\n",
       "  \u001b[1m(subject, rev_subject_rel, artist)\u001b[0m={ edge_index=[2, 3648] },\n",
       "  \u001b[1m(training_node, rev_training_rel, artist)\u001b[0m={ edge_index=[2, 130] },\n",
       "  \u001b[1m(field, rev_field_rel, artist)\u001b[0m={ edge_index=[2, 323] },\n",
       "  \u001b[1m(movement, rev_movement_rel, artist)\u001b[0m={ edge_index=[2, 286] },\n",
       "  \u001b[1m(people, rev_patrons_rel, artist)\u001b[0m={ edge_index=[2, 45] },\n",
       "  \u001b[1m(media, rev_media_rel, artwork)\u001b[0m={ edge_index=[2, 56347] },\n",
       "  \u001b[1m(tag, rev_about_rel, artwork)\u001b[0m={ edge_index=[2, 186612] },\n",
       "  \u001b[1m(genre, rev_genre_rel, artwork)\u001b[0m={ edge_index=[2, 61820] },\n",
       "  \u001b[1m(style, rev_style_rel, artwork)\u001b[0m={ edge_index=[2, 63157] },\n",
       "  \u001b[1m(artist, rev_author_rel, artwork)\u001b[0m={ edge_index=[2, 61477] },\n",
       "  \u001b[1m(period, rev_period_rel, artwork)\u001b[0m={ edge_index=[2, 5160] },\n",
       "  \u001b[1m(serie, rev_serie_rel, artwork)\u001b[0m={ edge_index=[2, 5152] },\n",
       "  \u001b[1m(artist, rev_patrons_rel, people)\u001b[0m={ edge_index=[2, 13] }\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomoGNN(torch.nn.Module):\n",
    "    def __init__(self, operator=GCNConv, activation=torch.nn.ReLU, input_channels=128, hidden_channels=16, out_channels=300, num_layers=1, dropout=0.5, bn=False, skip=False):\n",
    "        super(HomoGNN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.skip = skip\n",
    "        self.bn = bn\n",
    "        self.activation = activation\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        #self.convs.append(operator(input_channels, hidden_channels))\n",
    "        for _ in range(num_layers):\n",
    "            conv = operator(-1, hidden_channels)\n",
    "            lin = Linear(-1, hidden_channels)\n",
    "            bn = torch.nn.BatchNorm1d(hidden_channels)\n",
    "            self.convs.append(conv)\n",
    "            self.lins.append(lin)\n",
    "            self.bns.append(bn)\n",
    "        self.conv_out = operator(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.skip:\n",
    "                x = conv(x, edge_index) + self.lins[i](x)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x= self.activation(x)\n",
    "            if self.training:\n",
    "                x = F.dropout(x, self.dropout)\n",
    "        x = self.conv_out(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomoSGNN(torch.nn.Module):\n",
    "    def __init__(self, operator, activation, input_channels, hidden_channels, out_channels, n_layers, dropout, bn, skip):\n",
    "        super(HomoSGNN, self).__init__()\n",
    "        self.gnn = HomoGNN(operator, activation, input_channels, hidden_channels, out_channels, n_layers, dropout, bn, skip)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return [self.gnn(x, edge_index)]\n",
    "\n",
    "class HomoMGNN(torch.nn.Module):\n",
    "    def __init__(self, operator, activation, input_channels, hidden_channels, out_channels, n_layers, dropout, bn, skip):\n",
    "        super(HomoMGNN, self).__init__()\n",
    "        self.gnn_artist = HomoGNN(operator, activation, input_channels, hidden_channels, out_channels['artist'], n_layers, dropout, bn, skip)\n",
    "        self.gnn_style = HomoGNN(operator, activation, input_channels, hidden_channels, out_channels['style'], n_layers, dropout, bn, skip)\n",
    "        self.gnn_genre = HomoGNN(operator, activation, input_channels, hidden_channels, out_channels['genre'], n_layers, dropout, bn, skip)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return [self.gnn_artist(x, edge_index), self.gnn_style(x, edge_index), self.gnn_genre(x, edge_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtGraphGCNBoost:\n",
    "    operator_registry = {\n",
    "        'SAGEConv': operators.SAGEConv,\n",
    "        'GraphConv': operators.GraphConv,\n",
    "        'GATConv': operators.GATConv,\n",
    "        'GCNConv': operators.GCNConv\n",
    "    }\n",
    "\n",
    "    activation_registry = {\n",
    "        'relu': torch.nn.ReLU(),\n",
    "        'prelu': torch.nn.PReLU()\n",
    "    }\n",
    "\n",
    "    map_id2labels = {\n",
    "        0: 'artist',\n",
    "        1: 'style',\n",
    "        2: 'genre'\n",
    "    }\n",
    "\n",
    "    map_labels2id = {\n",
    "        'artist': 0,\n",
    "        'style': 1,\n",
    "        'genre': 2\n",
    "    }\n",
    "\n",
    "    def __init__(self, args, training_mode='multi_task'):\n",
    "        \n",
    "        self.traning_mode = training_mode\n",
    "        assert training_mode in ['multi_task', 'single_task']\n",
    "        assert args.operator in self.operator_registry.keys()\n",
    "\n",
    "        self.base_data, self.data, self.y, self.model, self.optimizer = self._bootstrap(args)\n",
    "        self.artworks = self.base_data[0]['artwork']\n",
    "        self.train_mask = self.artworks.train_mask\n",
    "        self.val_mask = self.artworks.val_mask\n",
    "        self.test_mask = self.artworks.test_mask\n",
    "\n",
    "    def _bootstrap(self, args):\n",
    "        base_data = ArtGraph(\"data\", preprocess='node2vec', transform=T.ToUndirected(), features=True, type='ekg')\n",
    "        data = base_data[0]\n",
    "        data = data.to_homogeneous()\n",
    "        if self.traning_mode == 'multi_task':\n",
    "            model = HomoMGNN(operator=self.operator_registry[args.operator],\n",
    "                                activation=self.activation_registry[args.activation],\n",
    "                                input_channels=base_data.num_features,\n",
    "                                hidden_channels=args.hidden,\n",
    "                                out_channels=base_data.num_classes,\n",
    "                                n_layers=args.nlayers,\n",
    "                                dropout=args.dropout,\n",
    "                                bn=args.bn,\n",
    "                                skip=args.skip)\n",
    "            y = torch.stack([base_data[0]['artwork'].y_artist, base_data[0]['artwork'].y_style, base_data[0]['artwork'].y_genre])\n",
    "        if self.traning_mode == 'single_task':\n",
    "            model = HomoSGNN(operator=self.operator_registry[args.operator],\n",
    "                                activation=self.activation_registry[args.activation],\n",
    "                                input_channels=base_data.num_features,\n",
    "                                hidden_channels=args.hidden,\n",
    "                                out_channels=base_data.num_classes[args.label],\n",
    "                                n_layers=args.nlayers,\n",
    "                                dropout=args.dropout,\n",
    "                                bn=args.bn,\n",
    "                                skip=args.skip)\n",
    "            y = torch.stack([base_data[0]['artwork'][f'y_{args.label}']])\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=3e-4)\n",
    "        \n",
    "        return base_data, data, y, model, optimizer\n",
    "    \n",
    "    def get_accuracy(self, predicted, labels):\n",
    "        return accuracy_score(labels, predicted.argmax(dim=1))\n",
    "\n",
    "    def get_accuracies_homo(self, predicted, labels, mask):\n",
    "        size = self.train_mask.shape[0]\n",
    "        accuracies = [] \n",
    "        for i, _ in enumerate(labels):\n",
    "            accuracies.append(self.get_accuracy(predicted[i][:size][mask], labels[i][mask]))\n",
    "        return accuracies\n",
    "\n",
    "    def get_loss(self, predicted, labels):\n",
    "        return F.nll_loss(predicted, labels.type(torch.LongTensor))\n",
    "    \n",
    "    def get_losses_homo(self, predicted, labels, mask):\n",
    "        size = self.train_mask.shape[0]\n",
    "        losses = []\n",
    "        for i, _ in enumerate(labels):\n",
    "            losses.append(self.get_loss(predicted[i][:size][mask], labels[i][mask]))\n",
    "        return losses\n",
    "\n",
    "    def get_precision_recall_homo(self, predicted, labels):\n",
    "        size = self.train_mask.shape[0]\n",
    "        cms = []\n",
    "        ps = []\n",
    "        rs = []\n",
    "        for i, _ in enumerate(labels):\n",
    "            y_true = labels[i][self.test_mask].numpy()\n",
    "            y_pred = predicted[i][:size][self.test_mask].argmax(dim=1).numpy()\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            cms.append(cm)\n",
    "            ps.append(precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "            rs.append(recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "        \n",
    "        return cms, ps, rs\n",
    "\n",
    "    def homo_training(self):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self.model(self.data.x, self.data.edge_index)\n",
    "\n",
    "        train_losses = self.get_losses_homo(out, self.y, self.train_mask)\n",
    "        train_total_loss = sum(train_losses)\n",
    "\n",
    "        train_total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        train_accuracies = self.get_accuracies_homo(out, self.y, self.train_mask)\n",
    "\n",
    "        return out, train_losses, train_accuracies\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def homo_test(self):\n",
    "        self.model.eval()\n",
    "        out = self.model(self.data.x, self.data.edge_index)\n",
    "        val_losses = self.get_losses_homo(out, self.y, self.val_mask)\n",
    "        test_losses = self.get_losses_homo(out, self.y, self.test_mask)\n",
    "\n",
    "        val_accuracies = self.get_accuracies_homo(out, self.y, self.val_mask)\n",
    "        test_accuracies = self.get_accuracies_homo(out, self.y, self.test_mask)\n",
    "\n",
    "        cms, ps, rs = self.get_precision_recall_homo(out, self.y)\n",
    "\n",
    "        return val_losses, val_accuracies, test_losses, test_accuracies, cms, ps, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--exp', type=str, default='default', help='Experiment name.')\n",
    "parser.add_argument('--type', type=str, default='homo', help='Graph type (hetero|homo).')\n",
    "parser.add_argument('--mode', type=str, default='single_task', help='Training mode (multi_task|single_task).')\n",
    "parser.add_argument('--label', type=str, default='genre', help='Label to predict (artist|style|genre).')\n",
    "parser.add_argument('--epochs', type=int, default=1, help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.')\n",
    "parser.add_argument('--hidden', type=int, default=16, help='Number of hidden units.')\n",
    "parser.add_argument('--nlayers', type=int, default=1, help='Number of layers.')\n",
    "parser.add_argument('--dropout', type=float, default=0, help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--operator', type=str, default='GCNConv', help='The graph convolutional operator.')\n",
    "parser.add_argument('--activation', type=str, default='prelu', help='The activation function.')\n",
    "parser.add_argument('--aggr', type=str, default='sum', help='Aggregation function.')\n",
    "parser.add_argument('--skip', action='store_true', default='False', help='Add skip connection.')\n",
    "parser.add_argument('--bn', action='store_true', default='True', help='Add batch normalization.')\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = ArtGraphGCNBoost(args, training_mode=args.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_train_loss 3.9765\n",
      "genre_train_accuracy 1.0\n",
      "genre_val_loss 3.9438\n",
      "genre_val_accuracy 3.0\n",
      "genre_test_loss 3.9491\n",
      "genre_test_accuracy 3.0\n",
      "genre_test_precision 0.7665308989110079\n",
      "genre_test_recall 0.9954619914462736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(0, args.epochs)):\n",
    "    out, train_losses, train_accuracies = gcn.homo_training()\n",
    "    val_losses, val_accuracies, test_losses, test_accuracies, cms, ps, rs = gcn.homo_test()\n",
    "    if epoch % 25 ==0:\n",
    "        if args.mode == 'multi_task':\n",
    "            for i, train_loss_acc in enumerate(zip(train_losses, train_accuracies)):\n",
    "                print(f'{gcn.map_id2labels[i]}_train_loss', round(train_loss_acc[0].detach().item(), 4))\n",
    "                print(f'{gcn.map_id2labels[i]}_train_accuracy', round(train_loss_acc[1].item(), 2) * 100)\n",
    "            for i, val_loss_acc in enumerate(zip(val_losses, val_accuracies)):\n",
    "                print(f'{gcn.map_id2labels[i]}_val_loss', round(val_loss_acc[0].detach().item(), 4))\n",
    "                print(f'{gcn.map_id2labels[i]}_val_accuracy', round(val_loss_acc[1].item(), 2) * 100)\n",
    "            for i, test_loss_acc_prec_rec in enumerate(zip(test_losses, test_accuracies, ps, rs)):\n",
    "                print(f'{gcn.map_id2labels[i]}_test_loss', round(test_loss_acc_prec_rec[0].detach().item(), 4))\n",
    "                print(f'{gcn.map_id2labels[i]}_test_accuracy', round(test_loss_acc_prec_rec[1].item(), 2) * 100)\n",
    "                print(f'{gcn.map_id2labels[i]}_precision', test_loss_acc_prec_rec[2] * 100)\n",
    "                print(f'{gcn.map_id2labels[i]}_recall', test_loss_acc_prec_rec[3] * 100)\n",
    "        if args.mode == 'single_task':\n",
    "            print(f'{args.label}_train_loss', round(train_losses[0].detach().item(), 4))\n",
    "            print(f'{args.label}_train_accuracy', round(train_accuracies[0].item(), 2) * 100)\n",
    "            print(f'{args.label}_val_loss', round(val_losses[0].detach().item(), 4))\n",
    "            print(f'{args.label}_val_accuracy', round(val_accuracies[0].item(), 2) * 100)\n",
    "            print(f'{args.label}_test_loss', round(test_losses[0].detach().item(), 4))\n",
    "            print(f'{args.label}_test_accuracy', round(test_accuracies[0].item(), 2) * 100)\n",
    "            print(f'{args.label}_test_precision', ps[0] * 100)\n",
    "            print(f'{args.label}_test_recall', rs[0] * 100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4cd95a69bfd7a84355187b639ae3e32d243eaa398007ea827fe1dce7201cea5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('thesis-project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
